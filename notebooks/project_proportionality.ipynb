{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook retrieves data from projects.csv file and calculates values of project proportionality across different impact areas and presents the corresponding graph. This file also plots the performance of City Idea Project and Green Million projects against the expected Equal Shares performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code block to set column and row viewing size/width\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', 30)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the metadata csv\n",
    "pbsummary_df = pd.read_csv('../metadata.csv', delimiter=';')\n",
    "pbsummary_df = pbsummary_df.drop_duplicates()\n",
    "pbsummary_df\n",
    "\n",
    "pbsummary_df['subunit'].fillna(value='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get election id and vote type, so we know better to segragate approval and score votings\n",
    "pbsummary_with_vote_type = pbsummary_df[['election_id', 'vote_type']]\n",
    "print(pbsummary_with_vote_type.head())\n",
    "print(pbsummary_with_vote_type['vote_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the projects CSV and loading to dataframe\n",
    "pbprojects_df = pd.read_csv('../projects.csv', delimiter=';')\n",
    "pbprojects_df.drop_duplicates(inplace=True)\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "# merge the column vote_type into pbprojects_df\n",
    "pbprojects_df = pd.merge(pbprojects_df, pbsummary_with_vote_type, on='election_id', how='inner')\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "pbprojects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows that there are 70 winning projects whose budget percent is 100%, uses the total budget\n",
    "full_budget_winners_projects = pbprojects_df[(pbprojects_df['budget_percent'] == 100) & ((pbprojects_df['is_greedy_winner'] == True) | (pbprojects_df['is_mes_winner'] == True))]\n",
    "print(full_budget_winners_projects.shape)\n",
    "print(full_budget_winners_projects['election_id'].unique())\n",
    "test_df = full_budget_winners_projects[(full_budget_winners_projects['is_mes_winner'] == True) & (full_budget_winners_projects['is_greedy_winner'] == False)]\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for projects where cost of a given project is zero\n",
    "\n",
    "print(\"Projects with zero costs: \", pbprojects_df[pbprojects_df['cost'] == 0])\n",
    "\n",
    "# Currently returns a single project ID which has been commented as been removed by City Council\n",
    "invalid_projects = pbprojects_df[pbprojects_df['cost'] == 0][['project_id','election_id']]\n",
    "print(invalid_projects)\n",
    "\n",
    "# Excluding that single project id by checking with particular election id and project id\n",
    "valid_pbprojects_df = pbprojects_df[~(pbprojects_df['project_id'].isin(invalid_projects['project_id']) & (pbprojects_df['election_id'].isin(invalid_projects['election_id'])))]\n",
    "print(pbprojects_df.shape)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Subunit empty projects count: \", valid_pbprojects_df['subunit'].isna().sum())\n",
    "\n",
    "empty_subunit_projects_df = valid_pbprojects_df[valid_pbprojects_df['subunit'].isna()][['election_id','project_id']]\n",
    "print(empty_subunit_projects_df.shape)\n",
    "print(empty_subunit_projects_df['election_id'].nunique())\n",
    "\n",
    "# There are citywide elections (unit-level); i.e. subunit is na, for such records fill na columns with values for subunit as all\n",
    "valid_pbprojects_df['subunit'].fillna(value='all', inplace=True)\n",
    "\n",
    "# Cross checking for projects where by we have filled with subunit equalling the value 'all'\n",
    "print(valid_pbprojects_df[valid_pbprojects_df['subunit'] == 'all'].shape)\n",
    "print(\"Valid PB projects are: \", valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up vote_percent column\n",
    "print(valid_pbprojects_df.shape)\n",
    "valid_pb_projects_total_selections = valid_pbprojects_df.groupby(['election_id'])['votes'].sum().reset_index()\n",
    "print(valid_pb_projects_total_selections.shape)\n",
    "valid_pb_projects_total_selections.rename(columns={'votes': 'total_votes_selection'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_total_selections, on='election_id', how='inner')\n",
    "valid_pbprojects_df['vote_percent'] = round((valid_pbprojects_df['votes'] / valid_pbprojects_df['total_votes_selection'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Election ids of city idea and green million\n",
    "aarau_election_id = valid_pbprojects_df[valid_pbprojects_df['country'] == 'Switzerland'].groupby(['election_id']).first().reset_index()['election_id']\n",
    "aarau_election_id = aarau_election_id.values[0]\n",
    "\n",
    "green_budget_election_id = valid_pbprojects_df[valid_pbprojects_df['unit'] == 'Wieliczka'].groupby(['election_id']).first().reset_index()['election_id']\n",
    "green_budget_election_id = green_budget_election_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distinct election IDs are: \", valid_pbprojects_df['election_id'].nunique())\n",
    "valid_pbprojects_df_grouped_election = valid_pbprojects_df.groupby(['election_id','is_mes_winner'])['cost'].agg(['sum']).reset_index()\n",
    "print(valid_pbprojects_df_grouped_election.head())\n",
    "print(valid_pbprojects_df_grouped_election.shape)\n",
    "print(\"Unique election IDs after grouping total costs: \", valid_pbprojects_df_grouped_election['election_id'].nunique())\n",
    "mes_winners_grouped_project_count = valid_pbprojects_df_grouped_election[valid_pbprojects_df_grouped_election['is_mes_winner'] == True]\n",
    "print(mes_winners_grouped_project_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting additional column for used budget with MES aggregation\n",
    "print(valid_pbprojects_df.shape)\n",
    "\n",
    "elections_with_mes_winners = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True]\n",
    "elections_with_greedy_winners = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner'] == True]\n",
    "print(\"Elections with MES winners: \", elections_with_mes_winners['election_id'].nunique())\n",
    "print(\"Elections with Greedy Winners: \", elections_with_greedy_winners['election_id'].nunique())\n",
    "\n",
    "# Getting the total budget usage for MES winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "valid_pb_projects_mes_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "valid_pb_projects_mes_budget_usage.rename(columns={'cost': 'mes_total_budget_usage'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_mes_budget_usage, on='election_id', how='inner')\n",
    "valid_pbprojects_df['mes_budget_usage_percent'] = round((valid_pbprojects_df['mes_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pbprojects_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total budget usage for utilitarian greedy winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "valid_pb_projects_greedy_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner']].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "valid_pb_projects_greedy_budget_usage.rename(columns={'cost': 'greedy_total_budget_usage'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_greedy_budget_usage, on='election_id', how='inner')\n",
    "valid_pbprojects_df['greedy_budget_usage_percent'] = round((valid_pbprojects_df['greedy_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill empty values for category with the label 'uncategorized' to aid in further data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pbprojects_df['category'].value_counts()\n",
    "\n",
    "# Checking to see if there are empty values for category in the entire project dataset\n",
    "na_category_count = valid_pbprojects_df['category'].isna().sum()\n",
    "print(\"Empty category values for PB projects are: \", na_category_count)\n",
    "\n",
    "# Fill such empty values of category with the label uncategorized, so that it can aid in further data preprocessing\n",
    "valid_pbprojects_df['category'].fillna('uncategorized', inplace=True)\n",
    "\n",
    "\n",
    "print(\"Emtpy category values after filling na: \", valid_pbprojects_df['category'].isna().sum())\n",
    "print(\"`uncategorized` category count for valid pb projects: \", valid_pbprojects_df[valid_pbprojects_df['category'] == 'uncategorized'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The column `category` contains multiple categories embedded into the column separated by commas, let's do some data processing so that we select only first signifiying category\n",
    "## We store this into a new column called `major_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimCategoryText(category_text):\n",
    "    return category_text.split(',')[0]\n",
    "\n",
    "valid_pbprojects_df['major_category'] = valid_pbprojects_df['category'].apply(trimCategoryText)\n",
    "valid_pbprojects_df['major_category'].nunique()\n",
    "\n",
    "print(\"Empty major category: \", valid_pbprojects_df['major_category'].isna().sum())\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"Counts for each major category: \\n\", valid_pbprojects_df['major_category'].value_counts())\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"Major categories sum: \", valid_pbprojects_df['major_category'].value_counts().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional columns for each category label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Categories column and create a set of unique categories\n",
    "categories_set = set(category.strip() for categories in valid_pbprojects_df['category'] for category in categories.split(','))\n",
    "\n",
    "# Create new columns with default value 0\n",
    "for category in categories_set:\n",
    "    valid_pbprojects_df[f'category_{category}'] = 0\n",
    "\n",
    "# Iterate through rows and update the new columns\n",
    "for index, row in valid_pbprojects_df.iterrows():\n",
    "    categories = row['category'].split(',')\n",
    "    for category in categories:\n",
    "        valid_pbprojects_df.at[index, f'category_{category.strip()}'] = 1\n",
    "    \n",
    "    if(len(categories) == 1 and (categories[0] == 'uncategorized')):\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = 0\n",
    "    else:\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = int(len(categories))\n",
    "\n",
    "valid_pbprojects_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"> Not sure if the above data is useful currently, but I will keep the data just in case, the dataset turns out to be useful for later cases </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if there are other labelled categories there were in between the commas but not in the major categories. This is not at a single project level, but the entire dataset level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_categories_list = valid_pbprojects_df['major_category'].unique().tolist()\n",
    "print(major_categories_list)\n",
    "unlisted_minor_categories = []\n",
    "\n",
    "for idx, row in valid_pbprojects_df.iterrows():\n",
    "    category_text = row['category']\n",
    "    cat_list = category_text.split(',')\n",
    "    for item in cat_list:\n",
    "        if item not in major_categories_list:\n",
    "            unlisted_minor_categories.append(item)\n",
    "\n",
    "\n",
    "print(\"Unlisted minor categories: \", unlisted_minor_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">\n",
    "<h5>The above value of empty unlisted minor categories means that it is sufficient to take note of the major categories only</h5>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each instance of PB normalize project costs with min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_grouped_max_pbprojects_df = valid_pbprojects_df.groupby(['election_id'])['cost'].max().reset_index()\n",
    "instance_grouped_max_pbprojects_df.rename(columns={'cost': 'election_project_max_cost'}, inplace=True)\n",
    "\n",
    "instance_grouped_min_pbprojects_df = valid_pbprojects_df.groupby(['election_id'])['cost'].min().reset_index()\n",
    "instance_grouped_min_pbprojects_df.rename(columns={'cost': 'election_project_min_cost'}, inplace=True)\n",
    "\n",
    "instance_grouped_total_projects_cost_df = valid_pbprojects_df.groupby(['election_id'])['cost'].sum().reset_index()\n",
    "instance_grouped_total_projects_cost_df.rename(columns={'cost': 'total_projects_cost'}, inplace=True)\n",
    "\n",
    "print(\"Valid PB Projects Shape before merge: \", valid_pbprojects_df.shape)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(instance_grouped_max_pbprojects_df, on='election_id', how='inner')\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(instance_grouped_min_pbprojects_df, on='election_id', how='inner')\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(instance_grouped_total_projects_cost_df, on='election_id', how='inner')\n",
    "print(\"After merge: \", valid_pbprojects_df.shape)\n",
    "\n",
    "def applyMinMaxNormalization(row):\n",
    "    if ((row['cost'] == row['election_project_max_cost']) & (row['cost'] == row['election_project_min_cost'])):\n",
    "        return 0.5\n",
    "    else:\n",
    "        return ((row['cost'] - row['election_project_min_cost']) / (row['election_project_max_cost'] - row['election_project_min_cost']))\n",
    "\n",
    "valid_pbprojects_df['normalized_cost'] = valid_pbprojects_df.apply(lambda row: applyMinMaxNormalization(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average normalized cost of entire pb instance, only greedy winners of instance, only mes winners of pb instance and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group valid_pbprojects_df and create a new dataframe for each grouped average results\n",
    "instance_overall_avg_cost = valid_pbprojects_df.groupby(['election_id'])['normalized_cost'].mean().reset_index()\n",
    "instance_overall_avg_cost.rename(columns={'normalized_cost': 'normalized_overall_avg_cost'}, inplace=True)\n",
    "\n",
    "instance_greedy_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_greedy_winner'] == True)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_greedy_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_greedy_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_avg_cost.merge(instance_greedy_winner_avg_cost, on='election_id', how='inner')\n",
    "\n",
    "\n",
    "instance_mes_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] == True)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_mes_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_mes_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_mes_winner_avg_cost, on='election_id', how='inner')\n",
    "\n",
    "instance_either_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] ==True) | (valid_pbprojects_df['is_greedy_winner'] == True)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_either_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_either_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_either_winner_avg_cost, on='election_id', how='inner')\n",
    "\n",
    "instance_neither_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] == False) & (valid_pbprojects_df['is_greedy_winner'] == False)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_neither_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_neither_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_neither_winner_avg_cost, on='election_id', how='left')\n",
    "\n",
    "instance_both_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] == True) & (valid_pbprojects_df['is_greedy_winner'] == True)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_both_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_both_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_both_winner_avg_cost, on='election_id', how='left')\n",
    "\n",
    "instance_only_greedy_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] == False) & (valid_pbprojects_df['is_greedy_winner'] == True)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_only_greedy_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_only_greedy_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_only_greedy_winner_avg_cost, on='election_id', how='left')\n",
    "\n",
    "instance_only_mes_winner_avg_cost = valid_pbprojects_df[(valid_pbprojects_df['is_mes_winner'] == True) & (valid_pbprojects_df['is_greedy_winner'] == False)].groupby('election_id')['normalized_cost'].mean().reset_index()\n",
    "instance_only_mes_winner_avg_cost.rename(columns={'normalized_cost': 'normalized_only_mes_avg_cost'}, inplace=True)\n",
    "instance_overall_df = instance_overall_df.merge(instance_only_mes_winner_avg_cost, on='election_id', how='left')\n",
    "\n",
    "# Fill non-existent values for instance_overall_df with values equal to -1. -1 because we had already normalized values between 0 and 1\n",
    "instance_overall_df.fillna(-1, inplace=True)\n",
    "print(instance_overall_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_df = valid_pbprojects_df\n",
    "categorization_df = categorization_df[[\n",
    "       'election_id', 'unit', 'subunit', 'instance', 'project_id', 'cost', 'target', 'total_projects_cost', 'votes', 'score', 'is_mes_winner', 'is_greedy_winner', 'is_phragmen_winner', 'category', 'category_public transit and roads',\n",
    "       'category_health', 'category_welfare', 'category_uncategorized',\n",
    "       'category_public space', 'category_urban greenery', 'category_culture',\n",
    "       'category_education', 'category_sport',\n",
    "       'category_environmental protection', 'category_labels_count'\n",
    "]]\n",
    "categorization_df.rename(columns={'category_education': 'education', 'category_public transit and roads': 'public_transit_and_roads', 'category_health': 'health', 'category_welfare': 'welfare', 'category_uncategorized':'uncategorized', 'category_public space': 'public_space', 'category_urban greenery': 'urban_greenery', 'category_culture': 'culture', 'category_sport': 'sport', 'category_environmental protection': 'env_protection', 'category_labels_count': 'total_tags' }, inplace=True)\n",
    "\n",
    "\n",
    "# In my earlier logic, I had put uncategorized to each undefined project categorization, however, this did not increase the total category counts. \n",
    "# So using this, we can the filter to remove uncategorized pb instances where uncategorized value is gre\n",
    "# ater than 0\n",
    "# Also, accordingly, uncategorized > 0 and total count values > 0 must not exists; sanity check\n",
    "empty_df = categorization_df[(categorization_df['uncategorized'] > 0) & (categorization_df['total_tags'] > 0)]\n",
    "print(\"Size of returned df must be 0: \", empty_df.shape)\n",
    "\n",
    "# Apply an additional filter to remove uncategorized values from the categorization_df\n",
    "print(\"Before applying filter shape of categorization DF is: \", categorization_df.shape)\n",
    "categorization_df = categorization_df[categorization_df['uncategorized'] == 0]\n",
    "print(\"After filtering, shape of categorization_df is: \", categorization_df.shape)\n",
    "## The output shape of 10830 x 22, matches with valid_pbprojects_df rows having major_category values other than `uncategorized`\n",
    "# So our data filtering is correct\n",
    "\n",
    "\n",
    "\n",
    "# Taking the sum of each category after having goruped by election id for mes_winners and rename the columns\n",
    "mes_winners_grouped_categorization_df = categorization_df[categorization_df['is_mes_winner'] == True].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "only_mes_winners_grouped_categorization_df = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "\n",
    "greedy_winners_grouped_categorization_df = categorization_df[categorization_df['is_greedy_winner'] == True].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "only_greedy_winners_grouped_categorization_df = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "\n",
    "# Apply filters to remove PB instances that have uncategorized datasets\n",
    "# Group by election IDs and sum the values of each category. If an instance has no values of the summed values in either categories, those are to be removed as uncategorized\n",
    "\n",
    "mes_winners_grouped_categorization_df\n",
    "\n",
    "\n",
    "# Create columns to store selection of percentages\n",
    "def addPercentageColumns(df):\n",
    "       categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "       # Create new columns for percentage values\n",
    "       for category in categories_set:\n",
    "              df[f'percentage_{category}'] = (df[category] / df['total_tags']) * 100\n",
    "\n",
    "# Apply the addPercentageColumns for each of the above 4 dataframes\n",
    "addPercentageColumns(mes_winners_grouped_categorization_df)\n",
    "addPercentageColumns(only_mes_winners_grouped_categorization_df)\n",
    "addPercentageColumns(greedy_winners_grouped_categorization_df)\n",
    "addPercentageColumns(only_greedy_winners_grouped_categorization_df)\n",
    "\n",
    "print(mes_winners_grouped_categorization_df.shape)\n",
    "\n",
    "pb_instance_with_labels = valid_pbprojects_df[valid_pbprojects_df['major_category'] != 'uncategorized'].groupby('election_id').count()\n",
    "print(\"PB instances with valid labels: \", pb_instance_with_labels.shape)\n",
    "# The row value from the above shape matches with the MES winners and Greedy winners after grouping\n",
    "\n",
    "mes_winners_grouped_categorization_df = mes_winners_grouped_categorization_df.add_prefix('mes_')\n",
    "greedy_winners_grouped_categorization_df = greedy_winners_grouped_categorization_df.add_prefix('greedy_')\n",
    "\n",
    "only_greedy_winners_grouped_categorization_df = only_greedy_winners_grouped_categorization_df.add_prefix('only_greedy_')\n",
    "only_mes_winners_grouped_categorization_df = only_mes_winners_grouped_categorization_df.add_prefix('only_mes_')\n",
    "\n",
    "winners_grouped_categorization_df = mes_winners_grouped_categorization_df.merge(greedy_winners_grouped_categorization_df, how='inner', on='election_id')\n",
    "\n",
    "# because only greedy has one more row (election instance) than only mes, verified by the code block below\n",
    "exclusive_winners_grouped_categorization_df = only_greedy_winners_grouped_categorization_df.merge(only_mes_winners_grouped_categorization_df, how='inner', on='election_id')\n",
    "\n",
    "# Verification to find the commonalities between only_mes and only_greedy grouped instances; uncomment to check!\n",
    "'''\n",
    "valid_only_mes_winners_election_ids = set(only_mes_winners_grouped_categorization_df.index.unique().to_list())\n",
    "valid_only_greedy_winners_election_ids = set(only_greedy_winners_grouped_categorization_df.index.unique().to_list())\n",
    "\n",
    "common_elections_count = len(valid_only_greedy_winners_election_ids.difference(valid_only_mes_winners_election_ids))\n",
    "print(common_elections_count)\n",
    "'''\n",
    "\n",
    "print(winners_grouped_categorization_df.shape)\n",
    "print(exclusive_winners_grouped_categorization_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat works here to merge the winners grouped data and exclusive winners data, because they share the common index\n",
    "grouped_categorization_df = pd.concat([winners_grouped_categorization_df, exclusive_winners_grouped_categorization_df], axis=1)\n",
    "print(grouped_categorization_df.shape)\n",
    "grouped_categorization_df\n",
    "\n",
    "# drop uncategorized and their respective % columns from the dataset, because they are all zero, since we filtered out uncategorized data earlier\n",
    "grouped_categorization_df.drop(columns=['mes_uncategorized', 'mes_percentage_uncategorized', 'greedy_uncategorized', 'greedy_percentage_uncategorized', 'only_mes_uncategorized', 'only_mes_percentage_uncategorized', 'only_greedy_uncategorized', 'only_greedy_percentage_uncategorized'], inplace=True)\n",
    "print(\"After dropping, new shape is: \", grouped_categorization_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sorted ordering for the 344 PB instances with their % values of winnings in each category for MES and Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some globals to be used for the code snippets below\n",
    "categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "category_title_map = {\n",
    "    'education': 'Education',\n",
    "    'public_transit_and_roads': 'Public Transit',\n",
    "    'health': 'Health',\n",
    "    'welfare': 'Welfare',\n",
    "    'public_space': 'Public Space',\n",
    "    'urban_greenery': 'Urban Greenery', \n",
    "    'culture': 'Culture', \n",
    "    'sport': 'Sport',\n",
    "    'env_protection': 'Env. Protection'\n",
    "}\n",
    "\n",
    "oneD_to_twoD_map = {\n",
    "    0: [0,0],\n",
    "    1: [0,1],\n",
    "    2: [0,2],\n",
    "    3: [1,0],\n",
    "    4: [1,1],\n",
    "    5: [1,2],\n",
    "    6: [2,0],\n",
    "    7: [2,1],\n",
    "    8: [2,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_categorization_df['diff_pct_education'] = grouped_categorization_df['greedy_percentage_education'] - grouped_categorization_df['mes_percentage_education'] \n",
    "grouped_categorization_df['diff_pct_health'] = grouped_categorization_df['greedy_percentage_health'] - grouped_categorization_df['mes_percentage_health']\n",
    "grouped_categorization_df['diff_pct_welfare'] = grouped_categorization_df['greedy_percentage_welfare'] - grouped_categorization_df['mes_percentage_welfare']\n",
    "grouped_categorization_df['diff_pct_sport'] = grouped_categorization_df['greedy_percentage_sport'] - grouped_categorization_df['mes_percentage_sport']\n",
    "grouped_categorization_df['diff_pct_public_space'] = grouped_categorization_df['greedy_percentage_public_space'] - grouped_categorization_df['mes_percentage_public_space']\n",
    "grouped_categorization_df['diff_pct_public_transit_and_roads'] = grouped_categorization_df['greedy_percentage_public_transit_and_roads'] - grouped_categorization_df['mes_percentage_public_transit_and_roads']\n",
    "grouped_categorization_df['diff_pct_env_protection'] = grouped_categorization_df['greedy_percentage_env_protection'] - grouped_categorization_df['mes_percentage_env_protection']\n",
    "grouped_categorization_df['diff_pct_culture'] = grouped_categorization_df['greedy_percentage_culture'] - grouped_categorization_df['mes_percentage_culture']\n",
    "grouped_categorization_df['diff_pct_urban_greenery'] = grouped_categorization_df['greedy_percentage_urban_greenery'] - grouped_categorization_df['mes_percentage_urban_greenery']\n",
    "\n",
    "grouped_categorization_df['only_diff_pct_education'] = grouped_categorization_df['only_greedy_percentage_education'] - grouped_categorization_df['only_mes_percentage_education'] \n",
    "grouped_categorization_df['only_diff_pct_health'] = grouped_categorization_df['only_greedy_percentage_health'] - grouped_categorization_df['only_mes_percentage_health']\n",
    "grouped_categorization_df['only_diff_pct_welfare'] = grouped_categorization_df['only_greedy_percentage_welfare'] - grouped_categorization_df['only_mes_percentage_welfare']\n",
    "grouped_categorization_df['only_diff_pct_sport'] = grouped_categorization_df['only_greedy_percentage_sport'] - grouped_categorization_df['only_mes_percentage_sport']\n",
    "grouped_categorization_df['only_diff_pct_public_space'] = grouped_categorization_df['only_greedy_percentage_public_space'] - grouped_categorization_df['only_mes_percentage_public_space']\n",
    "grouped_categorization_df['only_diff_pct_public_transit_and_roads'] = grouped_categorization_df['only_greedy_percentage_public_transit_and_roads'] - grouped_categorization_df['only_mes_percentage_public_transit_and_roads']\n",
    "grouped_categorization_df['only_diff_pct_env_protection'] = grouped_categorization_df['only_greedy_percentage_env_protection'] - grouped_categorization_df['only_mes_percentage_env_protection']\n",
    "grouped_categorization_df['only_diff_pct_culture'] = grouped_categorization_df['only_greedy_percentage_culture'] - grouped_categorization_df['only_mes_percentage_culture']\n",
    "grouped_categorization_df['only_diff_pct_urban_greenery'] = grouped_categorization_df['only_greedy_percentage_urban_greenery'] - grouped_categorization_df['only_mes_percentage_urban_greenery']\n",
    "\n",
    "\n",
    "grouped_categorization_df_na_removed = grouped_categorization_df.dropna()\n",
    "\n",
    "# Check the output of two different values just for confirmation\n",
    "# grouped_categorization_df[['mes_percentage_health', 'greedy_percentage_health', 'diff_pct_health', 'only_diff_pct_education', 'only_greedy_percentage_education', 'only_mes_percentage_education']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the categorization_df dataframe as a base and add new metrics necessary for calculating cost utilization and relative winners for each category of each PB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of categorization_df : \", categorization_df.shape)\n",
    "\n",
    "# for each category; add columns that signify the total cost of each category per PB instance\n",
    "# Create columns to store selection of percentages\n",
    "categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_total_cost'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 4 columns that denote; MES Winners Projects Count, MES Winners Project Costs, Greedy Winners Projects Count and Greedy Winners Project Cost; (overall)\n",
    "election_grouped_mes_winners_total_cost = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_mes_winners_total_cost.rename(columns={'cost': 'mes_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_greedy_winners_total_cost = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_greedy_winners_total_cost.rename(columns={'cost': 'greedy_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_mes_winners_total_project_count = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_mes_winners_total_project_count.rename(columns={'project_id': 'mes_winners_projects_count'}, inplace=True)\n",
    "\n",
    "election_grouped_greedy_winners_total_project_count = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_greedy_winners_total_project_count.rename(columns={'project_id': 'greedy_winners_projects_count'}, inplace=True)\n",
    "\n",
    "# Merge these dataset with categorization_df\n",
    "categorization_df = categorization_df.merge(election_grouped_mes_winners_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_greedy_winners_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_mes_winners_total_project_count, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_greedy_winners_total_project_count, on='election_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another 4 columns that denote; only MES Winners Projects Count, only MES Winners Project Costs, only Greedy Winners Projects Count and only Greedy Winners Project Cost; (overall)\n",
    "election_grouped_only_mes_winners_total_cost = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_only_mes_winners_total_cost.rename(columns={'cost': 'only_mes_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_only_greedy_winners_total_cost = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_only_greedy_winners_total_cost.rename(columns={'cost': 'only_greedy_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_only_mes_winners_total_project_count = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_only_mes_winners_total_project_count.rename(columns={'project_id': 'only_mes_winners_projects_count'}, inplace=True)\n",
    "\n",
    "election_grouped_only_greedy_winners_total_project_count = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_only_greedy_winners_total_project_count.rename(columns={'project_id': 'only_greedy_winners_projects_count'}, inplace=True)\n",
    "\n",
    "# Merge these dataset with categorization_df; for only, we will need to use left join, because there can be cases where\n",
    "# both outcomes are the same, in such cases only values don't exist; so left join is needed\n",
    "categorization_df = categorization_df.merge(election_grouped_only_mes_winners_total_cost, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_greedy_winners_total_cost, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_mes_winners_total_project_count, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_greedy_winners_total_project_count, on='election_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categorization_df with pbsummary to get total projects in all elections\n",
    "pbsummary_num_votes = pbsummary_df[['election_id', 'num_projects']]\n",
    "categorization_df = categorization_df.merge(pbsummary_num_votes, on='election_id', how='inner')\n",
    "categorization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total cost of each category in each election for greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    greedy_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    greedy_winners_category_grouped_df.rename(columns={'cost': f'greedy_winners_{category}_total_cost'}, inplace=True)\n",
    "    \n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(greedy_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_winners_{category}_total_cost'].fillna(0, inplace=True)\n",
    "\n",
    "# Adding total cost of each category in each election for MES winners\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    mes_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    mes_winners_category_grouped_df.rename(columns={'cost': f'mes_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(mes_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'mes_winners_{category}_total_cost'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category; just overall, not winners in any sense\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'greedy_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_winners_{category}_projects_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'mes_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'mes_winners_{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'only_greedy_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_greedy_winners_{category}_projects_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'only_mes_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_mes_winners_{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'only_greedy_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_greedy_winners_{category}_total_cost'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'only_mes_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_mes_winners_{category}_total_cost'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Metrics for Budget Share and Winning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics calculation required for relative winners\n",
    "print(\"Current shape of categorization df is: \", categorization_df.shape)\n",
    "\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_total_cost'] / categorization_df['greedy_winners_total_cost']\n",
    "    categorization_df[f'mes_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_total_cost'] / categorization_df['mes_winners_total_cost']\n",
    "    categorization_df[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] = categorization_df[f'greedy_relative_winners_cost_pct_{category}'] - categorization_df[f'mes_relative_winners_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'greedy_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_projects_count'] / categorization_df['greedy_winners_projects_count']\n",
    "    categorization_df[f'mes_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_projects_count'] / categorization_df['mes_winners_projects_count']\n",
    "    categorization_df[f'diff_greedy_mes_relative_winners_count_pct_{category}'] = categorization_df[f'greedy_relative_winners_count_pct_{category}'] - categorization_df[f'mes_relative_winners_count_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_total_cost'] / categorization_df['only_greedy_winners_total_cost']\n",
    "    categorization_df[f'only_mes_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_total_cost'] / categorization_df['only_mes_winners_total_cost']\n",
    "    categorization_df[f'diff_go_mo_relative_winners_cost_pct_{category}'] = categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] - categorization_df[f'only_mes_relative_winners_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_projects_count'] / categorization_df[f'only_greedy_winners_projects_count']\n",
    "    categorization_df[f'only_mes_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_projects_count'] / categorization_df[f'only_mes_winners_projects_count']\n",
    "    categorization_df[f'diff_go_mo_relative_winners_count_pct_{category}'] = categorization_df[f'only_greedy_relative_winners_count_pct_{category}'] - categorization_df[f'only_mes_relative_winners_count_pct_{category}']\n",
    "\n",
    "print(\"After adding new columns, shape should increase by 108 cols: \", categorization_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional metrics for average; relative winners cost / number\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_winners_avg_cost_{category}'] = categorization_df[f'greedy_relative_winners_cost_pct_{category}'] / categorization_df[f'greedy_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'mes_relative_winners_avg_cost_{category}'] = categorization_df[f'mes_relative_winners_cost_pct_{category}'] / categorization_df[f'mes_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'diff_ug_mes_relative_winners_avg_cost_{category}'] = categorization_df[f'greedy_relative_winners_avg_cost_{category}'] - categorization_df[f'mes_relative_winners_avg_cost_{category}'] \n",
    "\n",
    "    categorization_df[f'only_greedy_relative_winners_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] / categorization_df[f'only_greedy_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'only_mes_relative_winners_avg_cost_{category}'] = categorization_df[f'only_mes_relative_winners_cost_pct_{category}'] / categorization_df[f'only_mes_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'diff_go_mo_relative_winners_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_winners_avg_cost_{category}'] - categorization_df[f'only_mes_relative_winners_avg_cost_{category}'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Cost and Project Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New metrics required relative proposals in each category\n",
    "print(\"Before adding new metrics, shape was: \", categorization_df.shape)\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'mes_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] = categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] - categorization_df[f'mes_relative_proposals_cost_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'greedy_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'mes_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] = categorization_df[f'greedy_relative_proposals_count_pct_{category}'] - categorization_df[f'mes_relative_proposals_count_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'only_mes_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'diff_go_mo_relative_proposals_cost_pct_{category}'] = categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] - categorization_df[f'only_mes_relative_proposals_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'only_mes_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'diff_go_mo_relative_proposals_count_pct_{category}'] = categorization_df[f'only_greedy_relative_proposals_count_pct_{category}'] - categorization_df[f'only_mes_relative_proposals_count_pct_{category}']\n",
    "\n",
    "print(\"After adding new columns, shape should increase by 108 cols: \", categorization_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional metrics for average of relative proposals\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_proposals_avg_cost_{category}'] = categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] / categorization_df[f'greedy_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'mes_relative_proposals_avg_cost_{category}'] = categorization_df[f'mes_relative_proposals_cost_pct_{category}'] / categorization_df[f'mes_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'diff_ug_mes_relative_proposals_avg_cost_{category}'] = categorization_df[f'greedy_relative_proposals_avg_cost_{category}'] - categorization_df[f'mes_relative_proposals_avg_cost_{category}'] \n",
    "\n",
    "    categorization_df[f'only_greedy_relative_proposals_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] / categorization_df[f'only_greedy_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'only_mes_relative_proposals_avg_cost_{category}'] = categorization_df[f'only_mes_relative_proposals_cost_pct_{category}'] / categorization_df[f'only_mes_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'diff_go_mo_relative_proposals_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_proposals_avg_cost_{category}'] - categorization_df[f'only_mes_relative_proposals_avg_cost_{category}'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Cost and Project Proportionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming the metrics required for calculation\n",
    "print(\"Shape of categorization_df before adding metrics: \", categorization_df.shape)\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_rr_cost_{category}'] = (categorization_df[f'greedy_winners_{category}_total_cost'] / categorization_df['greedy_winners_total_cost']) / (categorization_df[f'{category}_total_cost'] / categorization_df['total_projects_cost'])\n",
    "    categorization_df[f'mes_rr_cost_{category}'] = (categorization_df[f'mes_winners_{category}_total_cost'] / categorization_df['mes_winners_total_cost']) / (categorization_df[f'{category}_total_cost'] / categorization_df['total_projects_cost'])\n",
    "    categorization_df[f'diff_greedy_mes_rr_cost_{category}'] = categorization_df[f'greedy_rr_cost_{category}'] - categorization_df[f'mes_rr_cost_{category}']\n",
    "\n",
    "    categorization_df[f'greedy_rr_projects_count_{category}'] = (categorization_df[f'greedy_winners_{category}_projects_count'] / categorization_df['greedy_winners_projects_count']) / (categorization_df[f'{category}_projects_count'] / categorization_df['num_projects'])\n",
    "    categorization_df[f'mes_rr_projects_count_{category}'] = (categorization_df[f'mes_winners_{category}_projects_count'] / categorization_df['mes_winners_projects_count']) / (categorization_df[f'{category}_projects_count'] / categorization_df['num_projects'])\n",
    "    categorization_df[f'diff_greedy_mes_rr_projects_count_{category}'] = categorization_df[f'greedy_rr_projects_count_{category}'] - categorization_df[f'mes_rr_projects_count_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_rr_cost_{category}'] = (categorization_df[f'only_greedy_winners_{category}_total_cost'] / categorization_df['only_greedy_winners_total_cost']) / (categorization_df[f'{category}_total_cost'] / categorization_df['total_projects_cost'])\n",
    "    categorization_df[f'only_mes_rr_cost_{category}'] = (categorization_df[f'only_mes_winners_{category}_total_cost'] / categorization_df['only_mes_winners_total_cost']) / (categorization_df[f'{category}_total_cost'] / categorization_df['total_projects_cost'])\n",
    "    categorization_df[f'diff_go_mo_rr_cost_{category}'] = categorization_df[f'only_greedy_rr_cost_{category}'] - categorization_df[f'only_mes_rr_cost_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_rr_projects_count_{category}'] = (categorization_df[f'only_greedy_winners_{category}_projects_count'] / categorization_df['only_greedy_winners_projects_count']) / (categorization_df[f'{category}_projects_count'] / categorization_df['num_projects'])\n",
    "    categorization_df[f'only_mes_rr_projects_count_{category}'] = (categorization_df[f'only_mes_winners_{category}_projects_count'] / categorization_df['only_mes_winners_projects_count']) / (categorization_df[f'{category}_projects_count'] / categorization_df['num_projects'])\n",
    "    categorization_df[f'diff_go_mo_rr_projects_count_{category}'] = categorization_df[f'only_greedy_rr_projects_count_{category}'] - categorization_df[f'only_mes_rr_projects_count_{category}']\n",
    "\n",
    "print(\"Shape should increase by 108 after adding metrics\")\n",
    "print(\"New shape is: \", categorization_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for Project Proportionality shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project proportionality ratio; UG vs ES; project count\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15), sharex=True, sharey=True)\n",
    "\n",
    "mes_heatmap_dict = {}\n",
    "greedy_heatmap_dict = {}\n",
    "for idx, category in enumerate(categories_set):\n",
    "    [x_pos, y_pos] = oneD_to_twoD_map[idx]\n",
    "    temp_df = categorization_df[['election_id', f'greedy_rr_projects_count_{category}', f'mes_rr_projects_count_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # threshold line\n",
    "    axes[x_pos][y_pos].axhline(y=1, color='black', label='Fair Representation = 1', linewidth=2)\n",
    "\n",
    "    greedy_rr_projects_count_category = temp_df[['election_id', f'greedy_rr_projects_count_{category}']].sort_values(by=f'greedy_rr_projects_count_{category}', ascending=False).reset_index()\n",
    "    greedy_rr_projects_count_category_avg = greedy_rr_projects_count_category[f'greedy_rr_projects_count_{category}'].mean()\n",
    "\n",
    "    mes_rr_projects_count_category = temp_df[['election_id', f'mes_rr_projects_count_{category}']].sort_values(by=f'mes_rr_projects_count_{category}', ascending=False).reset_index()    \n",
    "    mes_rr_projects_count_category_avg = mes_rr_projects_count_category[f'mes_rr_projects_count_{category}'].mean()\n",
    "\n",
    "    axes[x_pos][y_pos].scatter(range(len(mes_rr_projects_count_category)), mes_rr_projects_count_category[f'mes_rr_projects_count_{category}'], label='ES', marker='*', s=42, facecolors='#72b6a1', alpha=0.4, color='blue')\n",
    "    axes[x_pos][y_pos].scatter(range(len(greedy_rr_projects_count_category)), greedy_rr_projects_count_category[f'greedy_rr_projects_count_{category}'], label='UG', marker='o', s=42, facecolors='#e99675', alpha=0.4, color='red')\n",
    "\n",
    "    # average line\n",
    "    axes[x_pos][y_pos].axhline(y=greedy_rr_projects_count_category_avg, color='red', linestyle='solid')\n",
    "    axes[x_pos][y_pos].axhline(y=mes_rr_projects_count_category_avg, color='blue', linestyle='dashed')\n",
    "\n",
    "    mes_rr_projects_count_category_avg = np.nanmean(mes_rr_projects_count_category[f'mes_rr_projects_count_{category}'])\n",
    "    greedy_rr_projects_count_category_avg = np.nanmean(greedy_rr_projects_count_category[f'greedy_rr_projects_count_{category}'])\n",
    "\n",
    "    rdi = (greedy_rr_projects_count_category_avg - mes_rr_projects_count_category_avg) / (greedy_rr_projects_count_category_avg)\n",
    "\n",
    "\n",
    "    axes[x_pos][y_pos].set_title(f'{category_title_map[category]} ({rdi:.2f})', fontsize=18, fontweight='bold')\n",
    "    # if x_pos == 0 and y_pos == 2:\n",
    "    #     axes[x_pos][y_pos].legend(handlelength=1.0, handletextpad=0.5, fontsize=14, frameon=False)\n",
    "\n",
    "    if x_pos == 1 and y_pos == 0:\n",
    "        axes[x_pos][y_pos].set_ylabel(\"Project Proportionality\", fontsize=20, fontweight='bold')\n",
    "\n",
    "    if x_pos == 2 and y_pos == 1:\n",
    "        axes[x_pos][y_pos].set_xlabel('Voting Instances (Sorted)', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    axes[x_pos][y_pos].tick_params(axis='both', labelsize=16)\n",
    "    axes[x_pos][y_pos].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "\n",
    "    # annotate text for avg values\n",
    "    axes[x_pos][y_pos].text(225, 2.25, f'ES Avg: {mes_rr_projects_count_category_avg:.2f}', fontsize=14)\n",
    "    axes[x_pos][y_pos].text(225, 1.75, f'UG Avg: {greedy_rr_projects_count_category_avg:.2f}', fontsize=14)\n",
    "\n",
    "    # Customize legend\n",
    "    handles, labels = axes[0][0].get_legend_handles_labels()\n",
    "\n",
    "    # Create legend outside of the main plot\n",
    "    fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.01, 1.04), ncols=3, frameon=False, fontsize=16)\n",
    "    fig.subplots_adjust(right=1)  # Adjust right side to fit legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code blocks for analysis of Green Million and City Idea Aarau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_share_cols = ['election_id']\n",
    "winning_rate_cols = ['election_id']\n",
    "cost_representation_cols = ['election_id']\n",
    "project_representation_cols = ['election_id']\n",
    "\n",
    "for category in categories_set:\n",
    "    budget_share_cols.append(f'greedy_relative_winners_cost_pct_{category}')\n",
    "    budget_share_cols.append(f'mes_relative_winners_cost_pct_{category}')\n",
    "    budget_share_cols.append(f'diff_greedy_mes_relative_winners_cost_pct_{category}')\n",
    "\n",
    "    winning_rate_cols.append(f'greedy_relative_winners_count_pct_{category}')\n",
    "    winning_rate_cols.append(f'mes_relative_winners_count_pct_{category}')\n",
    "    winning_rate_cols.append(f'diff_greedy_mes_relative_winners_count_pct_{category}')\n",
    "\n",
    "    cost_representation_cols.append(f'greedy_relative_proposals_cost_pct_{category}')\n",
    "    cost_representation_cols.append(f'mes_relative_proposals_cost_pct_{category}')\n",
    "    cost_representation_cols.append(f'diff_greedy_mes_relative_proposals_cost_pct_{category}')\n",
    "\n",
    "    project_representation_cols.append(f'greedy_relative_proposals_count_pct_{category}')\n",
    "    project_representation_cols.append(f'mes_relative_proposals_count_pct_{category}')\n",
    "    project_representation_cols.append(f'diff_greedy_mes_relative_proposals_count_pct_{category}')\n",
    "\n",
    "\n",
    "budget_share_df = categorization_df[budget_share_cols]\n",
    "budget_share_df.drop_duplicates(inplace=True)\n",
    "\n",
    "winning_rate_df = categorization_df[winning_rate_cols]\n",
    "winning_rate_df.drop_duplicates(inplace=True)\n",
    "\n",
    "cost_representation_df = categorization_df[cost_representation_cols]\n",
    "cost_representation_df.drop_duplicates(inplace=True)\n",
    "\n",
    "project_representation_df = categorization_df[project_representation_cols]\n",
    "project_representation_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bs_impact = {}\n",
    "sd_bs_impact = {}\n",
    "\n",
    "avg_wr_impact = {}\n",
    "sd_wr_impact = {}\n",
    "\n",
    "avg_cr_impact = {}\n",
    "sd_cr_impact = {}\n",
    "\n",
    "avg_pr_impact = {}\n",
    "sd_pr_impact = {}\n",
    "\n",
    "zm_bs_impact = {}\n",
    "zm_wr_impact = {}\n",
    "zm_cr_impact = {}\n",
    "zm_pr_impact = {}\n",
    "\n",
    "aa_bs_impact = {}\n",
    "aa_wr_impact = {}\n",
    "aa_cr_impact = {}\n",
    "aa_pr_impact = {}\n",
    "\n",
    "for category in categories_set:\n",
    "    print(\"Current category: \", category)\n",
    "    # for budget share\n",
    "    bs_diff_avg = budget_share_df[f'diff_greedy_mes_relative_winners_cost_pct_{category}'].mean()\n",
    "    bs_diff_sd = budget_share_df[f'diff_greedy_mes_relative_winners_cost_pct_{category}'].std()\n",
    "    avg_bs_impact[category] = round(bs_diff_avg, 3)\n",
    "    sd_bs_impact[category] = round(bs_diff_sd, 3)\n",
    "    \n",
    "    zm_bs_diff_avg = budget_share_df[budget_share_df['election_id'] == green_budget_election_id][f'diff_greedy_mes_relative_winners_cost_pct_{category}'].mean()\n",
    "    zm_bs_impact[category] = round(zm_bs_diff_avg, 3)\n",
    "    aa_bs_diff_avg = budget_share_df[budget_share_df['election_id'] == aarau_election_id][f'diff_greedy_mes_relative_winners_cost_pct_{category}'].mean()\n",
    "    aa_bs_impact[category] = round(aa_bs_diff_avg, 3)\n",
    "\n",
    "    # for winning rate\n",
    "    wr_diff_avg = winning_rate_df[f'diff_greedy_mes_relative_winners_count_pct_{category}'].mean()\n",
    "    wr_diff_sd = winning_rate_df[f'diff_greedy_mes_relative_winners_count_pct_{category}'].std()\n",
    "    avg_wr_impact[category] = round(wr_diff_avg, 3)\n",
    "    sd_wr_impact[category] = round(wr_diff_sd, 3)\n",
    "\n",
    "    zm_wr_diff_avg = winning_rate_df[winning_rate_df['election_id'] == green_budget_election_id][f'diff_greedy_mes_relative_winners_count_pct_{category}'].mean()\n",
    "    zm_wr_impact[category] = round(zm_wr_diff_avg, 3)\n",
    "    aa_wr_diff_avg = winning_rate_df[winning_rate_df['election_id'] == aarau_election_id][f'diff_greedy_mes_relative_winners_count_pct_{category}'].mean()\n",
    "    aa_wr_impact[category] = round(aa_wr_diff_avg, 3)\n",
    "\n",
    "    # for cost representation\n",
    "    cr_diff_avg = cost_representation_df[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'].mean()\n",
    "    cr_diff_sd = cost_representation_df[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'].std()\n",
    "    avg_cr_impact[category] = round(cr_diff_avg, 3)\n",
    "    sd_cr_impact[category] = round(cr_diff_sd, 3)\n",
    "\n",
    "    zm_cr_diff_avg = cost_representation_df[cost_representation_df['election_id'] == green_budget_election_id][f'diff_greedy_mes_relative_proposals_cost_pct_{category}'].mean()\n",
    "    zm_cr_impact[category] = round(zm_cr_diff_avg, 3)\n",
    "    aa_cr_diff_avg = cost_representation_df[cost_representation_df['election_id'] == aarau_election_id][f'diff_greedy_mes_relative_proposals_cost_pct_{category}'].mean()\n",
    "    aa_cr_impact[category] = round(aa_cr_diff_avg, 3)\n",
    "\n",
    "    # for project representation\n",
    "    pr_diff_avg = project_representation_df[f'diff_greedy_mes_relative_proposals_count_pct_{category}'].mean()\n",
    "    pr_diff_sd = project_representation_df[f'diff_greedy_mes_relative_proposals_count_pct_{category}'].std()\n",
    "    avg_pr_impact[category] = round(pr_diff_avg, 3)\n",
    "    sd_pr_impact[category] = round(pr_diff_sd, 3)\n",
    "    \n",
    "    zm_pr_diff_avg = project_representation_df[project_representation_df['election_id'] == green_budget_election_id][f'diff_greedy_mes_relative_proposals_count_pct_{category}'].mean()\n",
    "    zm_pr_impact[category] = round(zm_pr_diff_avg, 3)\n",
    "    aa_pr_diff_avg = project_representation_df[project_representation_df['election_id'] == aarau_election_id][f'diff_greedy_mes_relative_proposals_count_pct_{category}'].mean()\n",
    "    aa_pr_impact[category] = round(aa_pr_diff_avg, 3)\n",
    "\n",
    "## manually fit health value for zm cr and pr to zero; because they were nan\n",
    "zm_cr_impact['health'] = 0\n",
    "zm_pr_impact['health'] = 0\n",
    "\n",
    "zm_cr_impact['culture'] = 0\n",
    "zm_pr_impact['culture'] = 0\n",
    "\n",
    "aa_cr_impact['public_space'] = 0\n",
    "aa_pr_impact['public_space'] = 0\n",
    "\n",
    "print(avg_bs_impact)\n",
    "print(avg_wr_impact)\n",
    "print(avg_cr_impact)\n",
    "print(avg_pr_impact)\n",
    "print(\"------------------------------\")\n",
    "print(zm_bs_impact)\n",
    "print(zm_wr_impact)\n",
    "print(zm_cr_impact)\n",
    "print(zm_pr_impact)\n",
    "print(\"------------------------------\")\n",
    "print(aa_bs_impact)\n",
    "print(aa_wr_impact)\n",
    "print(aa_cr_impact)\n",
    "print(aa_pr_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mapping of labels\n",
    "cmap = {\n",
    "    'education': 'Education',\n",
    "    'public_transit_and_roads': 'Public\\nTransit',\n",
    "    'health': 'Health',\n",
    "    'welfare': 'Welfare',\n",
    "    'public_space': 'Public\\nSpace',\n",
    "    'urban_greenery': 'Urban\\nGreenery',\n",
    "    'culture': 'Culture',\n",
    "    'sport': 'Sport',\n",
    "    'env_protection': 'Environmental\\nProtection'\n",
    "}\n",
    "xlabells = []\n",
    "\n",
    "for k, v in avg_bs_impact.items():\n",
    "    print(k)\n",
    "    xlabells.append(cmap[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "avg_bs_values = [v for _, v in avg_bs_impact.items()]\n",
    "avg_bs_values = np.array(avg_bs_values)\n",
    "sd_bs_values = [v for v in sd_bs_impact.values()]\n",
    "sd_bs_values = np.array(sd_bs_values)\n",
    "zm_bs_values = [v for _, v in zm_bs_impact.items()]\n",
    "aa_bs_values = [v for _, v in aa_bs_impact.items()]\n",
    "\n",
    "avg_wr_values = [v for v in avg_wr_impact.values()]\n",
    "avg_wr_values = np.array(avg_wr_values)\n",
    "sd_wr_values = [v for v in sd_wr_impact.values()]\n",
    "sd_wr_values = np.array(sd_wr_values)\n",
    "zm_wr_values = [v for v in zm_wr_impact.values()]\n",
    "aa_wr_values = [v for v in aa_wr_impact.values()]\n",
    "\n",
    "avg_cr_values = [v for v in avg_cr_impact.values()]\n",
    "avg_cr_values = np.array(avg_cr_values)\n",
    "sd_cr_values = [v for v in sd_cr_impact.values()]\n",
    "sd_cr_values = np.array(sd_cr_values)\n",
    "zm_cr_values = [v for v in zm_cr_impact.values()]\n",
    "aa_cr_values = [v for v in aa_cr_impact.values()]\n",
    "\n",
    "avg_pr_values = [v for v in avg_pr_impact.values()]\n",
    "avg_pr_values = np.array(avg_pr_values)\n",
    "sd_pr_values = [v for v in sd_pr_impact.values()]\n",
    "sd_pr_values = np.array(sd_pr_values)\n",
    "zm_pr_values = [v for v in zm_pr_impact.values()]\n",
    "aa_pr_values = [v for v in aa_pr_impact.values()]\n",
    "\n",
    "axes[0].plot(range(len(avg_bs_values)), avg_bs_values, color='r', label='Mean [All Voting Instances]', marker='o', markersize=8)\n",
    "axes[0].fill_between(range(len(avg_bs_values)), avg_bs_values - sd_bs_values, avg_bs_values + sd_bs_values, color='#c994c7', alpha=0.3, label='Standard Error [All voting Instances]')\n",
    "axes[0].plot(range(len(zm_bs_values)), zm_bs_values, color='g', label='Green Million [Wieliczka]', marker='D', markersize=8, linestyle='--')\n",
    "axes[0].plot(range(len(aa_bs_values)), aa_bs_values, color='b', label='City Idea [Aarau]', marker='*', markersize=8, linestyle='--')\n",
    "axes[0].set_title('Budget Share', loc='left', fontsize=14)\n",
    "axes[0].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "\n",
    "\n",
    "axes[1].plot(range(len(avg_wr_values)), avg_wr_values, color='r', label='Overall', marker='o', markersize=8)\n",
    "axes[1].fill_between(range(len(avg_wr_values)), avg_wr_values - sd_wr_values, avg_wr_values + sd_wr_values, color='#c994c7', alpha=0.3)\n",
    "axes[1].plot(range(len(zm_wr_values)), zm_wr_values, color='g', label='Zielony Milion', marker='D', markersize=8, linestyle='--')\n",
    "axes[1].plot(range(len(aa_wr_values)), aa_wr_values, color='b', label='Stadt Aaarau', marker='*', markersize=8, linestyle='--')\n",
    "axes[1].set_title('Winning Rate', loc='left', fontsize=14)\n",
    "axes[1].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "\n",
    "axes[2].plot(range(len(avg_cr_values)), avg_cr_values, color='r', label='Overall', marker='o', markersize=8)\n",
    "axes[2].fill_between(range(len(avg_cr_values)), avg_cr_values - sd_cr_values, avg_cr_values + sd_cr_values, color='#c994c7', alpha=0.3)\n",
    "axes[2].plot(range(len(zm_cr_values)), zm_cr_values, color='g', label='Zielony Milion', marker='D', markersize=8, linestyle='--')\n",
    "axes[2].plot(range(len(aa_cr_values)), aa_cr_values, color='b', label='Stadt Aaarau', marker='*', markersize=8, linestyle='--')\n",
    "axes[2].set_title('Cost Representation', loc='left', fontsize=14)\n",
    "axes[2].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "\n",
    "axes[3].plot(range(len(avg_pr_values)), avg_pr_values, color='r', label='Overall', marker='o', markersize=8)\n",
    "axes[3].fill_between(range(len(avg_pr_values)), avg_pr_values - sd_pr_values, avg_pr_values + sd_pr_values, color='#c994c7', alpha=0.3)\n",
    "axes[3].plot(range(len(zm_pr_values)), zm_pr_values, color='g', label='Zielony Milion', marker='D', markersize=8, linestyle='--')\n",
    "axes[3].plot(range(len(aa_pr_values)), aa_pr_values, color='b', label='Stadt Aaarau', marker='*', markersize=8, linestyle='--')\n",
    "axes[3].set_title('Project Representation', loc='left', fontsize=14)\n",
    "axes[3].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[3].set_xticks(range(len(avg_pr_values)))\n",
    "axes[3].set_xticklabels(xlabells)\n",
    "\n",
    "# Customize legend\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "# Create legend outside of the main plot\n",
    "fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=5, frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "fig.text(0, 0.5, 'Impact Loss', ha='center', va='center', rotation='vertical', fontsize=16)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pabutools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
