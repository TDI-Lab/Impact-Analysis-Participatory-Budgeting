{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook plots the loss by equal shares across different impact areas in terms of 3 proposed impact metrics with 3 varieties each- cost share, project share, popularity share; cost representation, project representation, popularity representation; cost proportionality, project proportionality, popularity proportionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code block to set column and row viewing size/width\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', 10)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the metadata csv\n",
    "pbsummary_df = pd.read_csv('../metadata.csv', delimiter=';')\n",
    "pbsummary_df = pbsummary_df.drop_duplicates()\n",
    "pbsummary_df\n",
    "\n",
    "pbsummary_aarau = pd.read_csv('../metadata_aarau.csv', delimiter=';')\n",
    "pbsummary_df = pd.concat([pbsummary_df, pbsummary_aarau], ignore_index=True)\n",
    "\n",
    "pbsummary_df['subunit'].fillna(value='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get election id and vote type, so we know better to segragate approval and score votings\n",
    "pbsummary_with_vote_type = pbsummary_df[['election_id', 'vote_type']]\n",
    "print(pbsummary_with_vote_type.head())\n",
    "print(pbsummary_with_vote_type['vote_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the projects CSV and loading to dataframe\n",
    "pbprojects_df = pd.read_csv('../projects.csv', delimiter=';')\n",
    "pbprojects_df.drop_duplicates(inplace=True)\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "pbprojects_aarau = pd.read_csv('../projects_aarau.csv', delimiter=';')\n",
    "pbprojects_df = pd.concat([pbprojects_df, pbprojects_aarau], ignore_index=True)\n",
    "\n",
    "# merge the column vote_type into pbprojects_df\n",
    "pbprojects_df = pd.merge(pbprojects_df, pbsummary_with_vote_type, on='election_id', how='inner')\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "pbprojects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for projects where cost of a given project is zero\n",
    "\n",
    "print(\"Projects with zero costs: \", pbprojects_df[pbprojects_df['cost'] == 0])\n",
    "\n",
    "# Currently returns a single project ID which has been commented as been removed by City Council\n",
    "invalid_projects = pbprojects_df[pbprojects_df['cost'] == 0][['project_id','election_id']]\n",
    "print(invalid_projects)\n",
    "\n",
    "# Excluding that single project id by checking with particular election id and project id\n",
    "valid_pbprojects_df = pbprojects_df[~(pbprojects_df['project_id'].isin(invalid_projects['project_id']) & (pbprojects_df['election_id'].isin(invalid_projects['election_id'])))]\n",
    "print(pbprojects_df.shape)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up vote_percent column\n",
    "print(valid_pbprojects_df.shape)\n",
    "valid_pb_projects_total_selections = valid_pbprojects_df.groupby(['election_id'])['votes'].sum().reset_index()\n",
    "print(valid_pb_projects_total_selections.shape)\n",
    "valid_pb_projects_total_selections.rename(columns={'votes': 'all_project_votes'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_total_selections, on='election_id', how='inner')\n",
    "valid_pbprojects_df['vote_percent'] = round((valid_pbprojects_df['votes'] / valid_pbprojects_df['all_project_votes'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aarau_election_id = valid_pbprojects_df[valid_pbprojects_df['country'] == 'Switzerland'].groupby(['election_id']).first().reset_index()['election_id']\n",
    "green_budget_election_id = valid_pbprojects_df[valid_pbprojects_df['unit'] == 'Wieliczka'].groupby(['election_id']).first().reset_index()['election_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Distinct election IDs are: \", valid_pbprojects_df['election_id'].nunique())\n",
    "# valid_pbprojects_df_grouped_election = valid_pbprojects_df.groupby(['election_id','is_mes_winner'])['cost'].agg(['sum']).reset_index()\n",
    "# print(valid_pbprojects_df_grouped_election.head())\n",
    "# print(valid_pbprojects_df_grouped_election.shape)\n",
    "# print(\"Unique election IDs after grouping total costs: \", valid_pbprojects_df_grouped_election['election_id'].nunique())\n",
    "# mes_winners_grouped_project_count = valid_pbprojects_df_grouped_election[valid_pbprojects_df_grouped_election['is_mes_winner'] == True]\n",
    "# print(mes_winners_grouped_project_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting additional column for used budget with MES aggregation\n",
    "# print(valid_pbprojects_df.shape)\n",
    "\n",
    "# elections_with_mes_winners = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True]\n",
    "# elections_with_greedy_winners = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner'] == True]\n",
    "# print(\"Elections with MES winners: \", elections_with_mes_winners['election_id'].nunique())\n",
    "# print(\"Elections with Greedy Winners: \", elections_with_greedy_winners['election_id'].nunique())\n",
    "\n",
    "# # Getting the total budget usage for MES winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "# valid_pb_projects_mes_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "# valid_pb_projects_mes_budget_usage.rename(columns={'cost': 'mes_total_budget_usage'}, inplace=True)\n",
    "# valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_mes_budget_usage, on='election_id', how='inner')\n",
    "# valid_pbprojects_df['mes_budget_usage_percent'] = round((valid_pbprojects_df['mes_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "# print(valid_pbprojects_df.shape)\n",
    "\n",
    "# # Getting the total budget usage for utilitarian greedy winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "# valid_pb_projects_greedy_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner']].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "# valid_pb_projects_greedy_budget_usage.rename(columns={'cost': 'greedy_total_budget_usage'}, inplace=True)\n",
    "# valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_greedy_budget_usage, on='election_id', how='inner')\n",
    "# valid_pbprojects_df['greedy_budget_usage_percent'] = round((valid_pbprojects_df['greedy_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "# print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill empty values for category with the label 'uncategorized' to aid in further data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pbprojects_df['category'].value_counts()\n",
    "\n",
    "# Checking to see if there are empty values for category in the entire project dataset\n",
    "na_category_count = valid_pbprojects_df['category'].isna().sum()\n",
    "print(\"Empty category values for PB projects are: \", na_category_count)\n",
    "\n",
    "# Fill such empty values of category with the label uncategorized, so that it can aid in further data preprocessing\n",
    "valid_pbprojects_df['category'].fillna('uncategorized', inplace=True)\n",
    "\n",
    "\n",
    "print(\"Emtpy category values after filling na: \", valid_pbprojects_df['category'].isna().sum())\n",
    "print(\"`uncategorized` category count for valid pb projects: \", valid_pbprojects_df[valid_pbprojects_df['category'] == 'uncategorized'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional columns for each category label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Categories column and create a set of unique categories\n",
    "categories_set = set(category.strip() for categories in valid_pbprojects_df['category'] for category in categories.split(','))\n",
    "\n",
    "# Create new columns with default value 0\n",
    "for category in categories_set:\n",
    "    valid_pbprojects_df[f'category_{category}'] = 0\n",
    "\n",
    "# Iterate through rows and update the new columns\n",
    "for index, row in valid_pbprojects_df.iterrows():\n",
    "    categories = row['category'].split(',')\n",
    "    for category in categories:\n",
    "        valid_pbprojects_df.at[index, f'category_{category.strip()}'] = 1\n",
    "    \n",
    "    if(len(categories) == 1 and (categories[0] == 'uncategorized')):\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = 0\n",
    "    else:\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = int(len(categories))\n",
    "\n",
    "valid_pbprojects_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_total_projects_cost_df = valid_pbprojects_df.groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_total_projects_cost_df.rename(columns={'cost': 'election_total_projects_cost'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(election_total_projects_cost_df, on='election_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_df = valid_pbprojects_df\n",
    "categorization_df = categorization_df[[\n",
    "       'election_id', 'unit', 'subunit', 'instance', 'project_id', 'vote_type', 'cost', 'election_total_projects_cost', 'votes', 'score', 'is_mes_winner', 'is_greedy_winner', 'is_phragmen_winner', 'category_public transit and roads',\n",
    "       'category_health', 'category_welfare', 'category_uncategorized',\n",
    "       'category_public space', 'category_urban greenery', 'category_culture',\n",
    "       'category_education', 'category_sport',\n",
    "       'category_environmental protection', 'category_labels_count'\n",
    "]]\n",
    "categorization_df.rename(columns={'category_education': 'education', 'category_public transit and roads': 'public_transit_and_roads', 'category_health': 'health', 'category_welfare': 'welfare', 'category_uncategorized':'uncategorized', 'category_public space': 'public_space', 'category_urban greenery': 'urban_greenery', 'category_culture': 'culture', 'category_sport': 'sport', 'category_environmental protection': 'env_protection', 'category_labels_count': 'total_tags' }, inplace=True)\n",
    "\n",
    "# update votes column to have score values for cumulative voting instances\n",
    "categorization_df['votes'] = np.where(categorization_df['vote_type'] == 'cumulative', categorization_df['score'], categorization_df['votes'])\n",
    "\n",
    "# In my earlier logic, I had put uncategorized to each undefined project categorization, however, this did not increase the total category counts. \n",
    "# So using this, we can the filter to remove uncategorized pb instances where uncategorized value is gre\n",
    "# ater than 0\n",
    "# Also, accordingly, uncategorized > 0 and total count values > 0 must not exists; sanity check\n",
    "empty_df = categorization_df[(categorization_df['uncategorized'] > 0) & (categorization_df['total_tags'] > 0)]\n",
    "print(\"Size of returned df must be 0: \", empty_df.shape)\n",
    "\n",
    "# Apply an additional filter to remove uncategorized values from the categorization_df\n",
    "categorization_df = categorization_df[categorization_df['uncategorized'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sorted ordering for the 344 PB instances with their % values of winnings in each category for MES and Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some globals to be used for the code snippets below\n",
    "categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "category_title_map = {\n",
    "    'education': 'Education',\n",
    "    'public_transit_and_roads': 'Public Transit',\n",
    "    'health': 'Health',\n",
    "    'welfare': 'Welfare',\n",
    "    'public_space': 'Public Space',\n",
    "    'urban_greenery': 'Urban Greenery', \n",
    "    'culture': 'Culture', \n",
    "    'sport': 'Sport',\n",
    "    'env_protection': 'Env. Protection'\n",
    "}\n",
    "\n",
    "oneD_to_twoD_map = {\n",
    "    0: [0,0],\n",
    "    1: [0,1],\n",
    "    2: [0,2],\n",
    "    3: [1,0],\n",
    "    4: [1,1],\n",
    "    5: [1,2],\n",
    "    6: [2,0],\n",
    "    7: [2,1],\n",
    "    8: [2,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the categorization_df dataframe as a base and add new metrics necessary for calculating cost utilization and relative winners for each category of each PB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winning totals for UG and ES; cost, projects, votes\n",
    "es_total_cost = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "es_total_cost.rename(columns={'cost': 'es_total_cost'}, inplace=True)\n",
    "\n",
    "ug_total_cost = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "ug_total_cost.rename(columns={'cost': 'ug_total_cost'}, inplace=True)\n",
    "\n",
    "es_total_projects = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "es_total_projects.rename(columns={'project_id': 'es_total_projects'}, inplace=True)\n",
    "\n",
    "ug_total_count = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "ug_total_count.rename(columns={'project_id': 'ug_total_projects'}, inplace=True)\n",
    "\n",
    "es_total_popularity = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['votes'].sum().reset_index()\n",
    "es_total_popularity.rename(columns={'votes': 'es_total_popularity'}, inplace=True)\n",
    "\n",
    "ug_total_popularity = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['votes'].sum().reset_index()\n",
    "ug_total_popularity.rename(columns={'votes': 'ug_total_popularity'}, inplace=True)\n",
    "\n",
    "# Merge these dataset with categorization_df\n",
    "categorization_df = categorization_df.merge(es_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(ug_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(es_total_projects, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(ug_total_count, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(es_total_popularity, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(ug_total_popularity, on='election_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of categorization_df : \", categorization_df.shape)\n",
    "\n",
    "# for each category; add columns that signify the total cost of each category per PB instance\n",
    "# Create columns to store selection of percentages\n",
    "\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # category total cost\n",
    "    category_total_cost = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    category_total_cost.rename(columns={'cost': f'{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # category total projects\n",
    "    category_total_projects = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    category_total_projects.rename(columns={'project_id': f'{category}_total_projects'}, inplace=True)\n",
    "\n",
    "    # category total popularity\n",
    "    category_total_popularity = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['votes'].sum().reset_index()\n",
    "    category_total_popularity.rename(columns={'votes': f'{category}_total_popularity'}, inplace=True)\n",
    "\n",
    "    # merge\n",
    "    categorization_df = categorization_df.merge(category_total_cost, how='left', on='election_id')\n",
    "    categorization_df = categorization_df.merge(category_total_projects, how='left', on='election_id')\n",
    "    categorization_df = categorization_df.merge(category_total_popularity, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_total_cost'].fillna(0, inplace=True)\n",
    "    categorization_df[f'{category}_total_projects'].fillna(0, inplace=True)\n",
    "    categorization_df[f'{category}_total_popularity'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categorization_df with pbsummary to get total projects in all elections\n",
    "pbsummary_num_votes = pbsummary_df[['election_id', 'num_projects']]\n",
    "categorization_df = categorization_df.merge(pbsummary_num_votes, on='election_id', how='inner')\n",
    "categorization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total cost of each category in each election for greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    greedy_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    greedy_winners_category_grouped_df.rename(columns={'cost': f'{category}_ug_total_cost'}, inplace=True)\n",
    "    \n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(greedy_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_ug_total_cost'].fillna(0, inplace=True)\n",
    "\n",
    "# Adding total cost of each category in each election for MES winners\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    mes_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    mes_winners_category_grouped_df.rename(columns={'cost': f'{category}_es_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(mes_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_es_total_cost'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'{category}_ug_total_projects'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_ug_total_projects'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'{category}_es_total_projects'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_es_total_projects'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Metrics for Budget Share and Winning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics calculation required for relative winners\n",
    "print(\"Current shape of categorization df is: \", categorization_df.shape)\n",
    "\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_ug_cost_share'] = 1 * categorization_df[f'{category}_ug_total_cost'] / categorization_df['ug_total_cost']\n",
    "    categorization_df[f'{category}_es_cost_share'] = 1 * categorization_df[f'{category}_es_total_cost'] / categorization_df['es_total_cost']\n",
    "    categorization_df[f'{category}_loss_cost_share'] = categorization_df[f'{category}_ug_cost_share'] - categorization_df[f'{category}_es_cost_share']\n",
    "\n",
    "    categorization_df[f'{category}_ug_project_share'] = 1 * categorization_df[f'{category}_ug_total_projects'] / categorization_df['ug_total_projects']\n",
    "    categorization_df[f'{category}_es_project_share'] = 1 * categorization_df[f'{category}_es_total_projects'] / categorization_df['es_total_projects']\n",
    "    categorization_df[f'{category}_loss_project_share'] = categorization_df[f'{category}_ug_project_share'] - categorization_df[f'{category}_es_project_share']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_color_map = {\n",
    "    'education': '#d53e4f',\n",
    "    'public_transit_and_roads': '#f46d43',\n",
    "    'health': '#fdae61',\n",
    "    'welfare': '#fee08b',\n",
    "    'public_space': '#ffffbf',\n",
    "    'urban_greenery': '#e6f598',\n",
    "    'culture': '#abdda4',\n",
    "    'sport': '#66c2a5',\n",
    "    'env_protection': '#3288bd'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Cost Representation and Project Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New metrics required relative proposals in each category\n",
    "print(\"Before adding new metrics, shape was: \", categorization_df.shape)\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_ug_cost_rep'] = 1 * categorization_df[f'{category}_ug_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'{category}_es_cost_rep'] = 1 * categorization_df[f'{category}_es_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'{category}_loss_cost_rep'] = categorization_df[f'{category}_ug_cost_rep'] - categorization_df[f'{category}_es_cost_rep']\n",
    "    \n",
    "    categorization_df[f'{category}_ug_project_rep'] = 1 * categorization_df[f'{category}_ug_total_projects'] / categorization_df[f'{category}_total_projects']\n",
    "    categorization_df[f'{category}_es_project_rep'] = 1 * categorization_df[f'{category}_es_total_projects'] / categorization_df[f'{category}_total_projects']\n",
    "    categorization_df[f'{category}_loss_project_rep'] = categorization_df[f'{category}_ug_project_rep'] - categorization_df[f'{category}_es_project_rep']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for Impact loss by Equal Shares for impact areas in terms of budget share, winning rate, cost representation and project representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "## first plot; budget share\n",
    "bsflippingPoints = {\n",
    "}\n",
    "\n",
    "bs_num_election_map = {\n",
    "}\n",
    "\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    bs_num_election_map[category] = temp_df[f'{category}_loss_cost_share'].count()\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_share']].sort_values(by=f'{category}_loss_cost_share', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'{category}_loss_cost_share'] > 0)):\n",
    "            bsflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "bsflippingPointsSorted = sorted(bsflippingPoints, key=bsflippingPoints.get)\n",
    "overall_bs_positive = []\n",
    "overall_bs_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(bsflippingPointsSorted):\n",
    "    # additional metrics for percentage representation\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = bsflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / bs_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_share']].sort_values(by=f'{category}_loss_cost_share', ascending=False).reset_index()\n",
    "\n",
    "    diff_relative_winners_cost_pct_category_avg = np.mean(diff_relative_winners_cost_pct_category[f'{category}_loss_cost_share'])\n",
    "    diff_relative_winners_cost_pct_category_positive_avg = np.mean(diff_relative_winners_cost_pct_category[diff_relative_winners_cost_pct_category[f'{category}_loss_cost_share'] > 0][f'{category}_loss_cost_share'])\n",
    "    diff_relative_winners_cost_pct_category_negative_avg = np.mean(diff_relative_winners_cost_pct_category[diff_relative_winners_cost_pct_category[f'{category}_loss_cost_share'] < 0][f'{category}_loss_cost_share'])\n",
    "\n",
    "    overall_bs_positive.append(diff_relative_winners_cost_pct_category_positive_avg)\n",
    "    overall_bs_negative.append(diff_relative_winners_cost_pct_category_negative_avg)\n",
    "\n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_winners_cost_pct_category_avg:.2f}; +{diff_relative_winners_cost_pct_category_positive_avg:.2f}; {diff_relative_winners_cost_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[0][0].plot(\n",
    "                i, row[f'{category}_loss_cost_share'],\n",
    "                marker='o' if row[f'{category}_loss_cost_share'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'{category}_loss_cost_share'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[0][0].plot(\n",
    "                    i, row[f'{category}_loss_cost_share'], \n",
    "                    marker='o' if row[f'{category}_loss_cost_share'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(bsflippingPointsSorted):\n",
    "    # threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_share']].sort_values(by=f'{category}_loss_cost_share', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = bsflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[0][0].plot(\n",
    "                    i, row[f'{category}_loss_cost_share'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_bs_positive_avg = np.mean(overall_bs_positive)\n",
    "overall_bs_negative_avg = np.mean(overall_bs_negative)\n",
    "\n",
    "axes[0][0].annotate(f'+{overall_bs_positive_avg:.2f}', xy=(0, 0), xytext=(50, 0.5), fontsize=20)\n",
    "axes[0][0].annotate(f'{overall_bs_negative_avg:.2f}', xy=(0, 0), xytext=(285, -0.7), fontsize=20)\n",
    "\n",
    "axes[0][0].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[0][0].set_title(\"A           Budget Share\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[0][0].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[0][0].tick_params(axis='both', labelsize=16)\n",
    "## end of first plot\n",
    "\n",
    "## second plot; winning rate\n",
    "wrflippingPoints = {\n",
    "}\n",
    "\n",
    "wr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    wr_num_election_map[category] = temp_df[f'{category}_loss_project_share'].count()\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'{category}_loss_project_share']].sort_values(by=f'{category}_loss_project_share', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'{category}_loss_project_share'] > 0)):\n",
    "            wrflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "wrflippingPointsSorted = sorted(wrflippingPoints, key=wrflippingPoints.get)\n",
    "\n",
    "overall_wr_positive = []\n",
    "overall_wr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(wrflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = wrflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / wr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'{category}_loss_project_share']].sort_values(by=f'{category}_loss_project_share', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_winners_count_pct_category_avg = np.mean(diff_relative_winners_count_pct_category[f'{category}_loss_project_share'])\n",
    "    diff_relative_winners_count_pct_category_positive_avg = np.mean(diff_relative_winners_count_pct_category[diff_relative_winners_count_pct_category[f'{category}_loss_project_share'] > 0][f'{category}_loss_project_share'])\n",
    "    diff_relative_winners_count_pct_category_negative_avg = np.mean(diff_relative_winners_count_pct_category[diff_relative_winners_count_pct_category[f'{category}_loss_project_share'] < 0][f'{category}_loss_project_share'])\n",
    "    \n",
    "    overall_wr_positive.append(diff_relative_winners_count_pct_category_positive_avg)\n",
    "    overall_wr_negative.append(diff_relative_winners_count_pct_category_negative_avg)\n",
    "    \n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_winners_count_pct_category_avg:.2f}; +{diff_relative_winners_count_pct_category_positive_avg:.2f}; {diff_relative_winners_count_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[0][1].plot(\n",
    "                i, row[f'{category}_loss_project_share'],\n",
    "                marker='o' if row[f'{category}_loss_project_share'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'{category}_loss_project_share'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[0][1].plot(\n",
    "                    i, row[f'{category}_loss_project_share'], \n",
    "                    marker='o' if row[f'{category}_loss_project_share'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(wrflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_share']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'{category}_loss_project_share']].sort_values(by=f'{category}_loss_project_share', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = wrflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[0][1].plot(\n",
    "                    i, row[f'{category}_loss_project_share'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_wr_positive_avg = np.mean(overall_wr_positive)\n",
    "overall_wr_negative_avg = np.mean(overall_wr_negative)\n",
    "\n",
    "axes[0][1].annotate(f'+{overall_wr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.5), fontsize=20)\n",
    "axes[0][1].annotate(f'{overall_wr_negative_avg:.2f}', xy=(0, 0), xytext=(250, -0.5), fontsize=20)\n",
    "\n",
    "axes[0][1].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[0][1].set_title(\"B           Winning Rate\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[0][1].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[0][0].tick_params(axis='both', labelsize=16)\n",
    "## end of second plot\n",
    "\n",
    "## third plot; cost representation\n",
    "crflippingPoints = {\n",
    "}\n",
    "\n",
    "cr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    cr_num_election_map[category] = temp_df[f'{category}_loss_cost_rep'].count()\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_rep']].sort_values(by=f'{category}_loss_cost_rep', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'{category}_loss_cost_rep'] > 0)):\n",
    "            crflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "crflippingPointsSorted = sorted(crflippingPoints, key=crflippingPoints.get)\n",
    "\n",
    "overall_cr_positive = []\n",
    "overall_cr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(crflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = crflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / cr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_rep']].sort_values(by=f'{category}_loss_cost_rep', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_proposals_cost_pct_category_avg = np.mean(diff_relative_proposals_cost_pct_category[f'{category}_loss_cost_rep'])\n",
    "    diff_relative_proposals_cost_pct_category_positive_avg = np.mean(diff_relative_proposals_cost_pct_category[diff_relative_proposals_cost_pct_category[f'{category}_loss_cost_rep'] > 0][f'{category}_loss_cost_rep'])\n",
    "    diff_relative_proposals_cost_pct_category_negative_avg = np.mean(diff_relative_proposals_cost_pct_category[diff_relative_proposals_cost_pct_category[f'{category}_loss_cost_rep'] < 0][f'{category}_loss_cost_rep'])\n",
    "    \n",
    "    overall_cr_positive.append(diff_relative_proposals_cost_pct_category_positive_avg)\n",
    "    overall_cr_negative.append(diff_relative_proposals_cost_pct_category_negative_avg)\n",
    "    \n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_proposals_cost_pct_category_avg:.2f}; +{diff_relative_proposals_cost_pct_category_positive_avg:.2f}; {diff_relative_proposals_cost_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[1][0].plot(\n",
    "                i, row[f'{category}_loss_cost_rep'],\n",
    "                marker='o' if row[f'{category}_loss_cost_rep'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'{category}_loss_cost_rep'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[1][0].plot(\n",
    "                    i, row[f'{category}_loss_cost_rep'], \n",
    "                    marker='o' if row[f'{category}_loss_cost_rep'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(crflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_cost_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'{category}_loss_cost_rep']].sort_values(by=f'{category}_loss_cost_rep', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = crflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[1][0].plot(\n",
    "                    i, row[f'{category}_loss_cost_rep'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_cr_positive_avg = np.mean(overall_cr_positive)\n",
    "overall_cr_negative_avg = np.mean(overall_cr_negative)\n",
    "\n",
    "axes[1][0].annotate(f'+{overall_cr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.75), fontsize=20)\n",
    "axes[1][0].annotate(f'{overall_cr_negative_avg:.2f}', xy=(0, 0), xytext=(50, -0.75), fontsize=20)\n",
    "\n",
    "axes[1][0].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[1][0].set_title(\"C      Cost Representation\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[1][0].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[1][0].tick_params(axis='both', labelsize=16)\n",
    "## end of third plot\n",
    "\n",
    "## fourth plot; project representation\n",
    "rrflippingPoints = {\n",
    "}\n",
    "\n",
    "rr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    rr_num_election_map[category] = temp_df[f'{category}_loss_project_rep'].count()\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'{category}_loss_project_rep']].sort_values(by=f'{category}_loss_project_rep', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'{category}_loss_project_rep'] > 0)):\n",
    "            rrflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "rrflippingPointsSorted = sorted(rrflippingPoints, key=rrflippingPoints.get)\n",
    "\n",
    "overall_rr_positive = []\n",
    "overall_rr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(rrflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = rrflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / rr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'{category}_loss_project_rep']].sort_values(by=f'{category}_loss_project_rep', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_proposals_count_pct_category_avg = np.mean(diff_relative_proposals_count_pct_category[f'{category}_loss_project_rep'])\n",
    "    diff_relative_proposals_count_pct_category_positive_avg = np.mean(diff_relative_proposals_count_pct_category[diff_relative_proposals_count_pct_category[f'{category}_loss_project_rep'] > 0][f'{category}_loss_project_rep'])\n",
    "    diff_relative_proposals_count_pct_category_negative_avg = np.mean(diff_relative_proposals_count_pct_category[diff_relative_proposals_count_pct_category[f'{category}_loss_project_rep'] < 0][f'{category}_loss_project_rep'])\n",
    "\n",
    "    overall_rr_positive.append(diff_relative_proposals_count_pct_category_positive_avg)\n",
    "    overall_rr_negative.append(diff_relative_proposals_count_pct_category_negative_avg)\n",
    "\n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_proposals_count_pct_category_avg:.2f}; +{diff_relative_proposals_count_pct_category_positive_avg:.2f}; {diff_relative_proposals_count_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[1][1].plot(\n",
    "                i, row[f'{category}_loss_project_rep'],\n",
    "                marker='o' if row[f'{category}_loss_project_rep'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'{category}_loss_project_rep'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[1][1].plot(\n",
    "                    i, row[f'{category}_loss_project_rep'], \n",
    "                    marker='o' if row[f'{category}_loss_project_rep'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(rrflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'{category}_loss_project_rep']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'{category}_loss_project_rep']].sort_values(by=f'{category}_loss_project_rep', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = rrflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[1][1].plot(\n",
    "                    i, row[f'{category}_loss_project_rep'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_rr_positive_avg = np.mean(overall_rr_positive)\n",
    "overall_rr_negative_avg = np.mean(overall_rr_negative)\n",
    "\n",
    "axes[1][1].annotate(f'+{overall_rr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.75), fontsize=20)\n",
    "axes[1][1].annotate(f'{overall_rr_negative_avg:.2f}', xy=(0, 0), xytext=(50, -0.75), fontsize=20)\n",
    "\n",
    "axes[1][1].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[1][1].set_title(\"D   Project Representation\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[1][1].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[1][1].tick_params(axis='both', labelsize=16)\n",
    "## end of fourth plot\n",
    "\n",
    "fig.text(0.5, -0.02, 'Voting Instances (Sorted)', fontsize=20, ha='center', va='center')\n",
    "fig.text(-0.02, 0.5, 'Impact Loss by Equal Shares (UG - ES)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pabutools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
