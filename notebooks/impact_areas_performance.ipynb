{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook plos the impact loss by equal shares across different impact areas in terms of 4 proposed impact metrics - budget share, winning rate, cost representation and project representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code block to set column and row viewing size/width\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', 30)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the metadata csv\n",
    "pbsummary_df = pd.read_csv('../metadata.csv', delimiter=';')\n",
    "pbsummary_df = pbsummary_df.drop_duplicates()\n",
    "pbsummary_df\n",
    "\n",
    "pbsummary_df['subunit'].fillna(value='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get election id and vote type, so we know better to segragate approval and score votings\n",
    "pbsummary_with_vote_type = pbsummary_df[['election_id', 'vote_type']]\n",
    "print(pbsummary_with_vote_type.head())\n",
    "print(pbsummary_with_vote_type['vote_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the projects CSV and loading to dataframe\n",
    "pbprojects_df = pd.read_csv('../projects.csv', delimiter=';')\n",
    "pbprojects_df.drop_duplicates(inplace=True)\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "# merge the column vote_type into pbprojects_df\n",
    "pbprojects_df = pd.merge(pbprojects_df, pbsummary_with_vote_type, on='election_id', how='inner')\n",
    "print(pbprojects_df.shape)\n",
    "\n",
    "pbprojects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for projects where cost of a given project is zero\n",
    "\n",
    "print(\"Projects with zero costs: \", pbprojects_df[pbprojects_df['cost'] == 0])\n",
    "\n",
    "# Currently returns a single project ID which has been commented as been removed by City Council\n",
    "invalid_projects = pbprojects_df[pbprojects_df['cost'] == 0][['project_id','election_id']]\n",
    "print(invalid_projects)\n",
    "\n",
    "# Excluding that single project id by checking with particular election id and project id\n",
    "valid_pbprojects_df = pbprojects_df[~(pbprojects_df['project_id'].isin(invalid_projects['project_id']) & (pbprojects_df['election_id'].isin(invalid_projects['election_id'])))]\n",
    "print(pbprojects_df.shape)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up vote_percent column\n",
    "print(valid_pbprojects_df.shape)\n",
    "valid_pb_projects_total_selections = valid_pbprojects_df.groupby(['election_id'])['votes'].sum().reset_index()\n",
    "print(valid_pb_projects_total_selections.shape)\n",
    "valid_pb_projects_total_selections.rename(columns={'votes': 'total_votes_selection'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_total_selections, on='election_id', how='inner')\n",
    "valid_pbprojects_df['vote_percent'] = round((valid_pbprojects_df['votes'] / valid_pbprojects_df['total_votes_selection'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aarau_election_id = valid_pbprojects_df[valid_pbprojects_df['country'] == 'Switzerland'].groupby(['election_id']).first().reset_index()['election_id']\n",
    "green_budget_election_id = valid_pbprojects_df[valid_pbprojects_df['unit'] == 'Wieliczka'].groupby(['election_id']).first().reset_index()['election_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distinct election IDs are: \", valid_pbprojects_df['election_id'].nunique())\n",
    "valid_pbprojects_df_grouped_election = valid_pbprojects_df.groupby(['election_id','is_mes_winner'])['cost'].agg(['sum']).reset_index()\n",
    "print(valid_pbprojects_df_grouped_election.head())\n",
    "print(valid_pbprojects_df_grouped_election.shape)\n",
    "print(\"Unique election IDs after grouping total costs: \", valid_pbprojects_df_grouped_election['election_id'].nunique())\n",
    "mes_winners_grouped_project_count = valid_pbprojects_df_grouped_election[valid_pbprojects_df_grouped_election['is_mes_winner'] == True]\n",
    "print(mes_winners_grouped_project_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting additional column for used budget with MES aggregation\n",
    "print(valid_pbprojects_df.shape)\n",
    "\n",
    "elections_with_mes_winners = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True]\n",
    "elections_with_greedy_winners = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner'] == True]\n",
    "print(\"Elections with MES winners: \", elections_with_mes_winners['election_id'].nunique())\n",
    "print(\"Elections with Greedy Winners: \", elections_with_greedy_winners['election_id'].nunique())\n",
    "\n",
    "# Getting the total budget usage for MES winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "valid_pb_projects_mes_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_mes_winner'] == True].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "valid_pb_projects_mes_budget_usage.rename(columns={'cost': 'mes_total_budget_usage'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_mes_budget_usage, on='election_id', how='inner')\n",
    "valid_pbprojects_df['mes_budget_usage_percent'] = round((valid_pbprojects_df['mes_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)\n",
    "\n",
    "# Getting the total budget usage for utilitarian greedy winning projects of each election_id (grouped) and adding a new column to denote that value\n",
    "valid_pb_projects_greedy_budget_usage = valid_pbprojects_df[valid_pbprojects_df['is_greedy_winner']].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "valid_pb_projects_greedy_budget_usage.rename(columns={'cost': 'greedy_total_budget_usage'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(valid_pb_projects_greedy_budget_usage, on='election_id', how='inner')\n",
    "valid_pbprojects_df['greedy_budget_usage_percent'] = round((valid_pbprojects_df['greedy_total_budget_usage'] / valid_pbprojects_df['total_budget'] * 100),3)\n",
    "print(valid_pbprojects_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill empty values for category with the label 'uncategorized' to aid in further data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pbprojects_df['category'].value_counts()\n",
    "\n",
    "# Checking to see if there are empty values for category in the entire project dataset\n",
    "na_category_count = valid_pbprojects_df['category'].isna().sum()\n",
    "print(\"Empty category values for PB projects are: \", na_category_count)\n",
    "\n",
    "# Fill such empty values of category with the label uncategorized, so that it can aid in further data preprocessing\n",
    "valid_pbprojects_df['category'].fillna('uncategorized', inplace=True)\n",
    "\n",
    "\n",
    "print(\"Emtpy category values after filling na: \", valid_pbprojects_df['category'].isna().sum())\n",
    "print(\"`uncategorized` category count for valid pb projects: \", valid_pbprojects_df[valid_pbprojects_df['category'] == 'uncategorized'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The column `category` contains multiple categories embedded into the column separated by commas, let's do some data processing so that we select only first signifiying category\n",
    "## We store this into a new column called `major_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimCategoryText(category_text):\n",
    "    return category_text.split(',')[0]\n",
    "\n",
    "valid_pbprojects_df['major_category'] = valid_pbprojects_df['category'].apply(trimCategoryText)\n",
    "valid_pbprojects_df['major_category'].nunique()\n",
    "\n",
    "print(\"Empty major category: \", valid_pbprojects_df['major_category'].isna().sum())\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"Counts for each major category: \\n\", valid_pbprojects_df['major_category'].value_counts())\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"Major categories sum: \", valid_pbprojects_df['major_category'].value_counts().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional columns for each category label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Categories column and create a set of unique categories\n",
    "categories_set = set(category.strip() for categories in valid_pbprojects_df['category'] for category in categories.split(','))\n",
    "\n",
    "# Create new columns with default value 0\n",
    "for category in categories_set:\n",
    "    valid_pbprojects_df[f'category_{category}'] = 0\n",
    "\n",
    "# Iterate through rows and update the new columns\n",
    "for index, row in valid_pbprojects_df.iterrows():\n",
    "    categories = row['category'].split(',')\n",
    "    for category in categories:\n",
    "        valid_pbprojects_df.at[index, f'category_{category.strip()}'] = 1\n",
    "    \n",
    "    if(len(categories) == 1 and (categories[0] == 'uncategorized')):\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = 0\n",
    "    else:\n",
    "        valid_pbprojects_df.at[index, 'category_labels_count'] = int(len(categories))\n",
    "\n",
    "valid_pbprojects_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_grouped_total_projects_cost_df = valid_pbprojects_df.groupby(['election_id'])['cost'].sum().reset_index()\n",
    "instance_grouped_total_projects_cost_df.rename(columns={'cost': 'total_projects_cost'}, inplace=True)\n",
    "valid_pbprojects_df = valid_pbprojects_df.merge(instance_grouped_total_projects_cost_df, on='election_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_df = valid_pbprojects_df\n",
    "categorization_df = categorization_df[[\n",
    "       'election_id', 'unit', 'subunit', 'instance', 'project_id', 'cost', 'total_projects_cost', 'votes', 'score', 'is_mes_winner', 'is_greedy_winner', 'is_phragmen_winner', 'category_public transit and roads',\n",
    "       'category_health', 'category_welfare', 'category_uncategorized',\n",
    "       'category_public space', 'category_urban greenery', 'category_culture',\n",
    "       'category_education', 'category_sport',\n",
    "       'category_environmental protection', 'category_labels_count'\n",
    "]]\n",
    "categorization_df.rename(columns={'category_education': 'education', 'category_public transit and roads': 'public_transit_and_roads', 'category_health': 'health', 'category_welfare': 'welfare', 'category_uncategorized':'uncategorized', 'category_public space': 'public_space', 'category_urban greenery': 'urban_greenery', 'category_culture': 'culture', 'category_sport': 'sport', 'category_environmental protection': 'env_protection', 'category_labels_count': 'total_tags' }, inplace=True)\n",
    "\n",
    "\n",
    "# In my earlier logic, I had put uncategorized to each undefined project categorization, however, this did not increase the total category counts. \n",
    "# So using this, we can the filter to remove uncategorized pb instances where uncategorized value is gre\n",
    "# ater than 0\n",
    "# Also, accordingly, uncategorized > 0 and total count values > 0 must not exists; sanity check\n",
    "empty_df = categorization_df[(categorization_df['uncategorized'] > 0) & (categorization_df['total_tags'] > 0)]\n",
    "print(\"Size of returned df must be 0: \", empty_df.shape)\n",
    "\n",
    "# Apply an additional filter to remove uncategorized values from the categorization_df\n",
    "print(\"Before applying filter shape of categorization DF is: \", categorization_df.shape)\n",
    "categorization_df = categorization_df[categorization_df['uncategorized'] == 0]\n",
    "print(\"After filtering, shape of categorization_df is: \", categorization_df.shape)\n",
    "## The output shape of 10830 x 22, matches with valid_pbprojects_df rows having major_category values other than `uncategorized`\n",
    "# So our data filtering is correct\n",
    "\n",
    "\n",
    "\n",
    "# Taking the sum of each category after having goruped by election id for mes_winners and rename the columns\n",
    "mes_winners_grouped_categorization_df = categorization_df[categorization_df['is_mes_winner'] == True].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "only_mes_winners_grouped_categorization_df = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "\n",
    "greedy_winners_grouped_categorization_df = categorization_df[categorization_df['is_greedy_winner'] == True].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "only_greedy_winners_grouped_categorization_df = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])[['public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'education', 'sport', 'env_protection', 'total_tags']].sum()\n",
    "\n",
    "# Apply filters to remove PB instances that have uncategorized datasets\n",
    "# Group by election IDs and sum the values of each category. If an instance has no values of the summed values in either categories, those are to be removed as uncategorized\n",
    "\n",
    "mes_winners_grouped_categorization_df\n",
    "\n",
    "\n",
    "# Create columns to store selection of percentages\n",
    "def addPercentageColumns(df):\n",
    "       categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'uncategorized', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "       # Create new columns for percentage values\n",
    "       for category in categories_set:\n",
    "              df[f'percentage_{category}'] = (df[category] / df['total_tags']) * 100\n",
    "\n",
    "# Apply the addPercentageColumns for each of the above 4 dataframes\n",
    "addPercentageColumns(mes_winners_grouped_categorization_df)\n",
    "addPercentageColumns(only_mes_winners_grouped_categorization_df)\n",
    "addPercentageColumns(greedy_winners_grouped_categorization_df)\n",
    "addPercentageColumns(only_greedy_winners_grouped_categorization_df)\n",
    "\n",
    "print(mes_winners_grouped_categorization_df.shape)\n",
    "\n",
    "pb_instance_with_labels = valid_pbprojects_df[valid_pbprojects_df['major_category'] != 'uncategorized'].groupby('election_id').count()\n",
    "print(\"PB instances with valid labels: \", pb_instance_with_labels.shape)\n",
    "# The row value from the above shape matches with the MES winners and Greedy winners after grouping\n",
    "\n",
    "mes_winners_grouped_categorization_df = mes_winners_grouped_categorization_df.add_prefix('mes_')\n",
    "greedy_winners_grouped_categorization_df = greedy_winners_grouped_categorization_df.add_prefix('greedy_')\n",
    "\n",
    "only_greedy_winners_grouped_categorization_df = only_greedy_winners_grouped_categorization_df.add_prefix('only_greedy_')\n",
    "only_mes_winners_grouped_categorization_df = only_mes_winners_grouped_categorization_df.add_prefix('only_mes_')\n",
    "\n",
    "winners_grouped_categorization_df = mes_winners_grouped_categorization_df.merge(greedy_winners_grouped_categorization_df, how='inner', on='election_id')\n",
    "\n",
    "# because only greedy has one more row (election instance) than only mes, verified by the code block below\n",
    "exclusive_winners_grouped_categorization_df = only_greedy_winners_grouped_categorization_df.merge(only_mes_winners_grouped_categorization_df, how='inner', on='election_id')\n",
    "\n",
    "# Verification to find the commonalities between only_mes and only_greedy grouped instances; uncomment to check!\n",
    "'''\n",
    "valid_only_mes_winners_election_ids = set(only_mes_winners_grouped_categorization_df.index.unique().to_list())\n",
    "valid_only_greedy_winners_election_ids = set(only_greedy_winners_grouped_categorization_df.index.unique().to_list())\n",
    "\n",
    "common_elections_count = len(valid_only_greedy_winners_election_ids.difference(valid_only_mes_winners_election_ids))\n",
    "print(common_elections_count)\n",
    "'''\n",
    "\n",
    "print(winners_grouped_categorization_df.shape)\n",
    "print(exclusive_winners_grouped_categorization_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat works here to merge the winners grouped data and exclusive winners data, because they share the common index\n",
    "grouped_categorization_df = pd.concat([winners_grouped_categorization_df, exclusive_winners_grouped_categorization_df], axis=1)\n",
    "print(grouped_categorization_df.shape)\n",
    "grouped_categorization_df\n",
    "\n",
    "# drop uncategorized and their respective % columns from the dataset, because they are all zero, since we filtered out uncategorized data earlier\n",
    "grouped_categorization_df.drop(columns=['mes_uncategorized', 'mes_percentage_uncategorized', 'greedy_uncategorized', 'greedy_percentage_uncategorized', 'only_mes_uncategorized', 'only_mes_percentage_uncategorized', 'only_greedy_uncategorized', 'only_greedy_percentage_uncategorized'], inplace=True)\n",
    "print(\"After dropping, new shape is: \", grouped_categorization_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sorted ordering for the 344 PB instances with their % values of winnings in each category for MES and Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some globals to be used for the code snippets below\n",
    "categories_set = ['education', 'public_transit_and_roads', 'health', 'welfare', 'public_space', 'urban_greenery', 'culture', 'sport', 'env_protection']\n",
    "\n",
    "category_title_map = {\n",
    "    'education': 'Education',\n",
    "    'public_transit_and_roads': 'Public Transit',\n",
    "    'health': 'Health',\n",
    "    'welfare': 'Welfare',\n",
    "    'public_space': 'Public Space',\n",
    "    'urban_greenery': 'Urban Greenery', \n",
    "    'culture': 'Culture', \n",
    "    'sport': 'Sport',\n",
    "    'env_protection': 'Env. Protection'\n",
    "}\n",
    "\n",
    "oneD_to_twoD_map = {\n",
    "    0: [0,0],\n",
    "    1: [0,1],\n",
    "    2: [0,2],\n",
    "    3: [1,0],\n",
    "    4: [1,1],\n",
    "    5: [1,2],\n",
    "    6: [2,0],\n",
    "    7: [2,1],\n",
    "    8: [2,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the categorization_df dataframe as a base and add new metrics necessary for calculating cost utilization and relative winners for each category of each PB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of categorization_df : \", categorization_df.shape)\n",
    "\n",
    "# for each category; add columns that signify the total cost of each category per PB instance\n",
    "# Create columns to store selection of percentages\n",
    "\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_total_cost'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 4 columns that denote; MES Winners Projects Count, MES Winners Project Costs, Greedy Winners Projects Count and Greedy Winners Project Cost; (overall)\n",
    "election_grouped_mes_winners_total_cost = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_mes_winners_total_cost.rename(columns={'cost': 'mes_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_greedy_winners_total_cost = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_greedy_winners_total_cost.rename(columns={'cost': 'greedy_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_mes_winners_total_project_count = categorization_df[(categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_mes_winners_total_project_count.rename(columns={'project_id': 'mes_winners_projects_count'}, inplace=True)\n",
    "\n",
    "election_grouped_greedy_winners_total_project_count = categorization_df[(categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_greedy_winners_total_project_count.rename(columns={'project_id': 'greedy_winners_projects_count'}, inplace=True)\n",
    "\n",
    "# Merge these dataset with categorization_df\n",
    "categorization_df = categorization_df.merge(election_grouped_mes_winners_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_greedy_winners_total_cost, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_mes_winners_total_project_count, on='election_id', how='inner')\n",
    "categorization_df = categorization_df.merge(election_grouped_greedy_winners_total_project_count, on='election_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another 4 columns that denote; only MES Winners Projects Count, only MES Winners Project Costs, only Greedy Winners Projects Count and only Greedy Winners Project Cost; (overall)\n",
    "election_grouped_only_mes_winners_total_cost = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_only_mes_winners_total_cost.rename(columns={'cost': 'only_mes_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_only_greedy_winners_total_cost = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "election_grouped_only_greedy_winners_total_cost.rename(columns={'cost': 'only_greedy_winners_total_cost'}, inplace=True)\n",
    "\n",
    "election_grouped_only_mes_winners_total_project_count = categorization_df[(categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_only_mes_winners_total_project_count.rename(columns={'project_id': 'only_mes_winners_projects_count'}, inplace=True)\n",
    "\n",
    "election_grouped_only_greedy_winners_total_project_count = categorization_df[(categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "election_grouped_only_greedy_winners_total_project_count.rename(columns={'project_id': 'only_greedy_winners_projects_count'}, inplace=True)\n",
    "\n",
    "# Merge these dataset with categorization_df; for only, we will need to use left join, because there can be cases where\n",
    "# both outcomes are the same, in such cases only values don't exist; so left join is needed\n",
    "categorization_df = categorization_df.merge(election_grouped_only_mes_winners_total_cost, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_greedy_winners_total_cost, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_mes_winners_total_project_count, on='election_id', how='left')\n",
    "categorization_df = categorization_df.merge(election_grouped_only_greedy_winners_total_project_count, on='election_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categorization_df with pbsummary to get total projects in all elections\n",
    "pbsummary_num_votes = pbsummary_df[['election_id', 'num_projects']]\n",
    "categorization_df = categorization_df.merge(pbsummary_num_votes, on='election_id', how='inner')\n",
    "categorization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total cost of each category in each election for greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    greedy_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    greedy_winners_category_grouped_df.rename(columns={'cost': f'greedy_winners_{category}_total_cost'}, inplace=True)\n",
    "    \n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(greedy_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_winners_{category}_total_cost'].fillna(0, inplace=True)\n",
    "\n",
    "# Adding total cost of each category in each election for MES winners\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    mes_winners_category_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    mes_winners_category_grouped_df.rename(columns={'cost': f'mes_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(mes_winners_category_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'mes_winners_{category}_total_cost'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category; just overall, not winners in any sense\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[categorization_df[category] == 1].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'greedy_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_winners_{category}_projects_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'mes_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'mes_winners_{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'only_greedy_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_greedy_winners_{category}_projects_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['project_id'].count().reset_index()\n",
    "    temp_grouped_df.rename(columns={'project_id': f'only_mes_winners_{category}_projects_count'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_mes_winners_{category}_projects_count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project counts in each category that are Greedy winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_greedy_winner'] == True) & (categorization_df['is_mes_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'only_greedy_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_greedy_winners_{category}_total_cost'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Project counts in each category that are MES Winners only\n",
    "# Perform grouping based on catgories and then add to respective costs columns\n",
    "for category in categories_set:\n",
    "    # temporarily grouped df \n",
    "    temp_grouped_df = categorization_df[(categorization_df[category] == 1) & (categorization_df['is_mes_winner'] == True) & (categorization_df['is_greedy_winner'] == False)].groupby(['election_id'])['cost'].sum().reset_index()\n",
    "    temp_grouped_df.rename(columns={'cost': f'only_mes_winners_{category}_total_cost'}, inplace=True)\n",
    "\n",
    "    # Check if not using assignment but just using left join works or not; of course it wouldn't work, because merge returns the results in an entirely different dataset\n",
    "    categorization_df = categorization_df.merge(temp_grouped_df, how='left', on='election_id')\n",
    "\n",
    "# For the above columns, there can be NA values, replace them with zeros\n",
    "for category in categories_set:\n",
    "    categorization_df[f'only_mes_winners_{category}_total_cost'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Metrics for Budget Share and Winning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics calculation required for relative winners\n",
    "print(\"Current shape of categorization df is: \", categorization_df.shape)\n",
    "\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_total_cost'] / categorization_df['greedy_winners_total_cost']\n",
    "    categorization_df[f'mes_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_total_cost'] / categorization_df['mes_winners_total_cost']\n",
    "    categorization_df[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] = categorization_df[f'greedy_relative_winners_cost_pct_{category}'] - categorization_df[f'mes_relative_winners_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'greedy_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_projects_count'] / categorization_df['greedy_winners_projects_count']\n",
    "    categorization_df[f'mes_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_projects_count'] / categorization_df['mes_winners_projects_count']\n",
    "    categorization_df[f'diff_greedy_mes_relative_winners_count_pct_{category}'] = categorization_df[f'greedy_relative_winners_count_pct_{category}'] - categorization_df[f'mes_relative_winners_count_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_total_cost'] / categorization_df['only_greedy_winners_total_cost']\n",
    "    categorization_df[f'only_mes_relative_winners_cost_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_total_cost'] / categorization_df['only_mes_winners_total_cost']\n",
    "    categorization_df[f'diff_go_mo_relative_winners_cost_pct_{category}'] = categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] - categorization_df[f'only_mes_relative_winners_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_projects_count'] / categorization_df[f'only_greedy_winners_projects_count']\n",
    "    categorization_df[f'only_mes_relative_winners_count_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_projects_count'] / categorization_df[f'only_mes_winners_projects_count']\n",
    "    categorization_df[f'diff_go_mo_relative_winners_count_pct_{category}'] = categorization_df[f'only_greedy_relative_winners_count_pct_{category}'] - categorization_df[f'only_mes_relative_winners_count_pct_{category}']\n",
    "\n",
    "print(\"After adding new columns, shape should increase by 108 cols: \", categorization_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional metrics for average; relative winners cost / number\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_winners_avg_cost_{category}'] = categorization_df[f'greedy_relative_winners_cost_pct_{category}'] / categorization_df[f'greedy_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'mes_relative_winners_avg_cost_{category}'] = categorization_df[f'mes_relative_winners_cost_pct_{category}'] / categorization_df[f'mes_relative_winners_count_pct_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_relative_winners_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_winners_cost_pct_{category}'] / categorization_df[f'only_greedy_relative_winners_count_pct_{category}']\n",
    "    categorization_df[f'only_mes_relative_winners_avg_cost_{category}'] = categorization_df[f'only_mes_relative_winners_cost_pct_{category}'] / categorization_df[f'only_mes_relative_winners_count_pct_{category}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_color_map = {\n",
    "    'education': '#d53e4f',\n",
    "    'public_transit_and_roads': '#f46d43',\n",
    "    'health': '#fdae61',\n",
    "    'welfare': '#fee08b',\n",
    "    'public_space': '#ffffbf',\n",
    "    'urban_greenery': '#e6f598',\n",
    "    'culture': '#abdda4',\n",
    "    'sport': '#66c2a5',\n",
    "    'env_protection': '#3288bd'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Cost Representation and Project Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New metrics required relative proposals in each category\n",
    "print(\"Before adding new metrics, shape was: \", categorization_df.shape)\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'mes_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] = categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] - categorization_df[f'mes_relative_proposals_cost_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'greedy_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'greedy_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'mes_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'mes_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] = categorization_df[f'greedy_relative_proposals_count_pct_{category}'] - categorization_df[f'mes_relative_proposals_count_pct_{category}']\n",
    "    \n",
    "    categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'only_mes_relative_proposals_cost_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_total_cost'] / categorization_df[f'{category}_total_cost']\n",
    "    categorization_df[f'diff_go_mo_relative_proposals_cost_pct_{category}'] = categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] - categorization_df[f'only_mes_relative_proposals_cost_pct_{category}']\n",
    "\n",
    "    categorization_df[f'only_greedy_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'only_greedy_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'only_mes_relative_proposals_count_pct_{category}'] = 1 * categorization_df[f'only_mes_winners_{category}_projects_count'] / categorization_df[f'{category}_projects_count']\n",
    "    categorization_df[f'diff_go_mo_relative_proposals_count_pct_{category}'] = categorization_df[f'only_greedy_relative_proposals_count_pct_{category}'] - categorization_df[f'only_mes_relative_proposals_count_pct_{category}']\n",
    "\n",
    "print(\"After adding new columns, shape should increase by 108 cols: \", categorization_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional metrics for average of relative proposals\n",
    "for category in categories_set:\n",
    "    categorization_df[f'greedy_relative_proposals_avg_cost_{category}'] = categorization_df[f'greedy_relative_proposals_cost_pct_{category}'] / categorization_df[f'greedy_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'mes_relative_proposals_avg_cost_{category}'] = categorization_df[f'mes_relative_proposals_cost_pct_{category}'] / categorization_df[f'mes_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'only_greedy_relative_proposals_avg_cost_{category}'] = categorization_df[f'only_greedy_relative_proposals_cost_pct_{category}'] / categorization_df[f'only_greedy_relative_proposals_count_pct_{category}']\n",
    "    categorization_df[f'only_mes_relative_proposals_avg_cost_{category}'] = categorization_df[f'only_mes_relative_proposals_cost_pct_{category}'] / categorization_df[f'only_mes_relative_proposals_count_pct_{category}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for Impact loss by Equal Shares for impact areas in terms of budget share, winning rate, cost representation and project representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "## first plot; budget share\n",
    "bsflippingPoints = {\n",
    "}\n",
    "\n",
    "bs_num_election_map = {\n",
    "}\n",
    "\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    bs_num_election_map[category] = temp_df[f'diff_greedy_mes_relative_winners_cost_pct_{category}'].count()\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_cost_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] > 0)):\n",
    "            bsflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "bsflippingPointsSorted = sorted(bsflippingPoints, key=bsflippingPoints.get)\n",
    "overall_bs_positive = []\n",
    "overall_bs_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(bsflippingPointsSorted):\n",
    "    # additional metrics for percentage representation\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = bsflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / bs_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_cost_pct_{category}', ascending=False).reset_index()\n",
    "\n",
    "    diff_relative_winners_cost_pct_category_avg = np.mean(diff_relative_winners_cost_pct_category[f'diff_greedy_mes_relative_winners_cost_pct_{category}'])\n",
    "    diff_relative_winners_cost_pct_category_positive_avg = np.mean(diff_relative_winners_cost_pct_category[diff_relative_winners_cost_pct_category[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] > 0][f'diff_greedy_mes_relative_winners_cost_pct_{category}'])\n",
    "    diff_relative_winners_cost_pct_category_negative_avg = np.mean(diff_relative_winners_cost_pct_category[diff_relative_winners_cost_pct_category[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] < 0][f'diff_greedy_mes_relative_winners_cost_pct_{category}'])\n",
    "\n",
    "    overall_bs_positive.append(diff_relative_winners_cost_pct_category_positive_avg)\n",
    "    overall_bs_negative.append(diff_relative_winners_cost_pct_category_negative_avg)\n",
    "\n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_winners_cost_pct_category_avg:.2f}; +{diff_relative_winners_cost_pct_category_positive_avg:.2f}; {diff_relative_winners_cost_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[0][0].plot(\n",
    "                i, row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'],\n",
    "                marker='o' if row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[0][0].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'], \n",
    "                    marker='o' if row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(bsflippingPointsSorted):\n",
    "    # threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_cost_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = bsflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_winners_cost_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[0][0].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_winners_cost_pct_{category}'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_bs_positive_avg = np.mean(overall_bs_positive)\n",
    "overall_bs_negative_avg = np.mean(overall_bs_negative)\n",
    "\n",
    "axes[0][0].annotate(f'+{overall_bs_positive_avg:.2f}', xy=(0, 0), xytext=(50, 0.5), fontsize=20)\n",
    "axes[0][0].annotate(f'{overall_bs_negative_avg:.2f}', xy=(0, 0), xytext=(285, -0.7), fontsize=20)\n",
    "\n",
    "axes[0][0].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[0][0].set_title(\"A           Budget Share\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[0][0].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[0][0].tick_params(axis='both', labelsize=16)\n",
    "## end of first plot\n",
    "\n",
    "## second plot; winning rate\n",
    "wrflippingPoints = {\n",
    "}\n",
    "\n",
    "wr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    wr_num_election_map[category] = temp_df[f'diff_greedy_mes_relative_winners_count_pct_{category}'].count()\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'diff_greedy_mes_relative_winners_count_pct_{category}'] > 0)):\n",
    "            wrflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "wrflippingPointsSorted = sorted(wrflippingPoints, key=wrflippingPoints.get)\n",
    "\n",
    "overall_wr_positive = []\n",
    "overall_wr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(wrflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = wrflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / wr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_winners_count_pct_category_avg = np.mean(diff_relative_winners_count_pct_category[f'diff_greedy_mes_relative_winners_count_pct_{category}'])\n",
    "    diff_relative_winners_count_pct_category_positive_avg = np.mean(diff_relative_winners_count_pct_category[diff_relative_winners_count_pct_category[f'diff_greedy_mes_relative_winners_count_pct_{category}'] > 0][f'diff_greedy_mes_relative_winners_count_pct_{category}'])\n",
    "    diff_relative_winners_count_pct_category_negative_avg = np.mean(diff_relative_winners_count_pct_category[diff_relative_winners_count_pct_category[f'diff_greedy_mes_relative_winners_count_pct_{category}'] < 0][f'diff_greedy_mes_relative_winners_count_pct_{category}'])\n",
    "    \n",
    "    overall_wr_positive.append(diff_relative_winners_count_pct_category_positive_avg)\n",
    "    overall_wr_negative.append(diff_relative_winners_count_pct_category_negative_avg)\n",
    "    \n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_winners_count_pct_category_avg:.2f}; +{diff_relative_winners_count_pct_category_positive_avg:.2f}; {diff_relative_winners_count_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[0][1].plot(\n",
    "                i, row[f'diff_greedy_mes_relative_winners_count_pct_{category}'],\n",
    "                marker='o' if row[f'diff_greedy_mes_relative_winners_count_pct_{category}'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'diff_greedy_mes_relative_winners_count_pct_{category}'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[0][1].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_winners_count_pct_{category}'], \n",
    "                    marker='o' if row[f'diff_greedy_mes_relative_winners_count_pct_{category}'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(wrflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_winners_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_winners_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_winners_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = wrflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_winners_count_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[0][1].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_winners_count_pct_{category}'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_wr_positive_avg = np.mean(overall_wr_positive)\n",
    "overall_wr_negative_avg = np.mean(overall_wr_negative)\n",
    "\n",
    "axes[0][1].annotate(f'+{overall_wr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.5), fontsize=20)\n",
    "axes[0][1].annotate(f'{overall_wr_negative_avg:.2f}', xy=(0, 0), xytext=(250, -0.5), fontsize=20)\n",
    "\n",
    "axes[0][1].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[0][1].set_title(\"B           Winning Rate\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[0][1].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[0][0].tick_params(axis='both', labelsize=16)\n",
    "## end of second plot\n",
    "\n",
    "## third plot; cost representation\n",
    "crflippingPoints = {\n",
    "}\n",
    "\n",
    "cr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    cr_num_election_map[category] = temp_df[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'].count()\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_cost_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] > 0)):\n",
    "            crflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "crflippingPointsSorted = sorted(crflippingPoints, key=crflippingPoints.get)\n",
    "\n",
    "overall_cr_positive = []\n",
    "overall_cr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(crflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = crflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / cr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_cost_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_proposals_cost_pct_category_avg = np.mean(diff_relative_proposals_cost_pct_category[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'])\n",
    "    diff_relative_proposals_cost_pct_category_positive_avg = np.mean(diff_relative_proposals_cost_pct_category[diff_relative_proposals_cost_pct_category[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] > 0][f'diff_greedy_mes_relative_proposals_cost_pct_{category}'])\n",
    "    diff_relative_proposals_cost_pct_category_negative_avg = np.mean(diff_relative_proposals_cost_pct_category[diff_relative_proposals_cost_pct_category[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] < 0][f'diff_greedy_mes_relative_proposals_cost_pct_{category}'])\n",
    "    \n",
    "    overall_cr_positive.append(diff_relative_proposals_cost_pct_category_positive_avg)\n",
    "    overall_cr_negative.append(diff_relative_proposals_cost_pct_category_negative_avg)\n",
    "    \n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_proposals_cost_pct_category_avg:.2f}; +{diff_relative_proposals_cost_pct_category_positive_avg:.2f}; {diff_relative_proposals_cost_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[1][0].plot(\n",
    "                i, row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'],\n",
    "                marker='o' if row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[1][0].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'], \n",
    "                    marker='o' if row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(crflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_cost_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_cost_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_cost_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = crflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_proposals_cost_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[1][0].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_proposals_cost_pct_{category}'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_cr_positive_avg = np.mean(overall_cr_positive)\n",
    "overall_cr_negative_avg = np.mean(overall_cr_negative)\n",
    "\n",
    "axes[1][0].annotate(f'+{overall_cr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.75), fontsize=20)\n",
    "axes[1][0].annotate(f'{overall_cr_negative_avg:.2f}', xy=(0, 0), xytext=(50, -0.75), fontsize=20)\n",
    "\n",
    "axes[1][0].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[1][0].set_title(\"C      Cost Representation\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[1][0].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[1][0].tick_params(axis='both', labelsize=16)\n",
    "## end of third plot\n",
    "\n",
    "## fourth plot; project representation\n",
    "rrflippingPoints = {\n",
    "}\n",
    "\n",
    "rr_num_election_map = {\n",
    "}\n",
    "\n",
    "# First loop through all categories to determine the order of flipping points\n",
    "for idx, category in enumerate(categories_set):\n",
    "    threshold_found = False\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    rr_num_election_map[category] = temp_df[f'diff_greedy_mes_relative_proposals_count_pct_{category}'].count()\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():\n",
    "        # Condition check for finding threshold\n",
    "        if (threshold_found  == False) and (~(row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] > 0)):\n",
    "            rrflippingPoints[category] = i\n",
    "            threshold_found = True\n",
    "            break\n",
    "\n",
    "rrflippingPointsSorted = sorted(rrflippingPoints, key=rrflippingPoints.get)\n",
    "\n",
    "overall_rr_positive = []\n",
    "overall_rr_negative = []\n",
    "\n",
    "# Second loop across all categories set to actually plot the lines in the flipping order\n",
    "for idx, category in enumerate(rrflippingPointsSorted):\n",
    "    \n",
    "    # additional metrics for percentage representation for categories in legends\n",
    "    num_elections = temp_df.shape[0]\n",
    "    flippingPointVal = rrflippingPoints[category]\n",
    "    flippingPointPct = 100 * flippingPointVal / rr_num_election_map[category]\n",
    "\n",
    "    cur_color = categories_color_map[category]\n",
    "    \n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    diff_relative_proposals_count_pct_category_avg = np.mean(diff_relative_proposals_count_pct_category[f'diff_greedy_mes_relative_proposals_count_pct_{category}'])\n",
    "    diff_relative_proposals_count_pct_category_positive_avg = np.mean(diff_relative_proposals_count_pct_category[diff_relative_proposals_count_pct_category[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] > 0][f'diff_greedy_mes_relative_proposals_count_pct_{category}'])\n",
    "    diff_relative_proposals_count_pct_category_negative_avg = np.mean(diff_relative_proposals_count_pct_category[diff_relative_proposals_count_pct_category[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] < 0][f'diff_greedy_mes_relative_proposals_count_pct_{category}'])\n",
    "\n",
    "    overall_rr_positive.append(diff_relative_proposals_count_pct_category_positive_avg)\n",
    "    overall_rr_negative.append(diff_relative_proposals_count_pct_category_negative_avg)\n",
    "\n",
    "    cur_category_label = f'{category_title_map[category]}: {flippingPointPct:.0f}%, [~{diff_relative_proposals_count_pct_category_avg:.2f}; +{diff_relative_proposals_count_pct_category_positive_avg:.2f}; {diff_relative_proposals_count_pct_category_negative_avg:.2f}]'\n",
    "\n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():\n",
    "        # additional condition to any specific row data, just for labeling\n",
    "        if i == 0:\n",
    "            axes[1][1].plot(\n",
    "                i, row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'],\n",
    "                marker='o' if row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] >= 0 else '*', \n",
    "                markerfacecolor= cur_color, \n",
    "                markeredgewidth=1, \n",
    "                markeredgecolor=cur_color if row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] >= 0 else 'none', \n",
    "                label=cur_category_label, \n",
    "                markersize=4, \n",
    "                alpha=0.8,\n",
    "                linestyle='none'\n",
    "            )\n",
    "        else:\n",
    "            axes[1][1].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'], \n",
    "                    marker='o' if row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'] >= 0 else '*', \n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgewidth=1, \n",
    "                    markeredgecolor=cur_color, \n",
    "                    markersize=4, \n",
    "                    alpha=0.8,\n",
    "                    linestyle='none'\n",
    "                )\n",
    "            \n",
    "# Third loop across to present the flipping point value on the outermost layer\n",
    "for idx, category in enumerate(rrflippingPointsSorted):\n",
    "    cur_color = categories_color_map[category]\n",
    "    temp_df = categorization_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    diff_relative_proposals_count_pct_category = temp_df[['election_id', f'diff_greedy_mes_relative_proposals_count_pct_{category}']].sort_values(by=f'diff_greedy_mes_relative_proposals_count_pct_{category}', ascending=False).reset_index()\n",
    "    \n",
    "    # additional variable to store flipping point value for the category\n",
    "    flippingPointVal = rrflippingPoints[category]\n",
    "\n",
    "    for i, row in diff_relative_proposals_count_pct_category.iterrows():  \n",
    "        # additional condition check to match the nth item for flipping point value\n",
    "        if (i == flippingPointVal):\n",
    "            # mark such observation with outer black edge color\n",
    "            axes[1][1].plot(\n",
    "                    i, row[f'diff_greedy_mes_relative_proposals_count_pct_{category}'], \n",
    "                    marker='o',\n",
    "                    markerfacecolor= cur_color, \n",
    "                    markeredgecolor='black', \n",
    "                )\n",
    "            \n",
    "overall_rr_positive_avg = np.mean(overall_rr_positive)\n",
    "overall_rr_negative_avg = np.mean(overall_rr_negative)\n",
    "\n",
    "axes[1][1].annotate(f'+{overall_rr_positive_avg:.2f}', xy=(0, 0), xytext=(10, 0.75), fontsize=20)\n",
    "axes[1][1].annotate(f'{overall_rr_negative_avg:.2f}', xy=(0, 0), xytext=(50, -0.75), fontsize=20)\n",
    "\n",
    "axes[1][1].legend(frameon=False, handlelength=1.0, handletextpad=0.5, fontsize=12)\n",
    "axes[1][1].set_title(\"D   Project Representation\", loc=\"left\", fontsize=22, fontdict={'fontweight': 'bold'})\n",
    "axes[1][1].grid(axis='both', which='major', color='gray', alpha=0.1)\n",
    "axes[1][1].tick_params(axis='both', labelsize=16)\n",
    "## end of fourth plot\n",
    "\n",
    "fig.text(0.5, -0.02, 'Voting Instances (Sorted)', fontsize=20, ha='center', va='center')\n",
    "fig.text(-0.02, 0.5, 'Impact Loss by Equal Shares (UG - ES)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pabutools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
